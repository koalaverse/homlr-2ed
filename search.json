[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hands-On Machine Learning with R, 2ed",
    "section": "",
    "text": "Welcome\nWelcome to the second edition of Hands-On Machine Learning with R. This book provides hands-on modules for many of the most common machine learning methods to include:\nYou will learn how to build and tune these various models with R packages that have been tested and approved due to their ability to scale well. However, our motivation in almost every case is to describe the techniques in a way that helps develop intuition for its strengths and weaknesses. For the most part, we minimize mathematical complexity when possible but also provide resources to get deeper into the details if desired.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#who-should-read-this",
    "href": "index.html#who-should-read-this",
    "title": "Hands-On Machine Learning with R, 2ed",
    "section": "Who should read this",
    "text": "Who should read this\nWe intend this work to be a practitioner’s guide to the machine learning process and a place where one can come to learn about the approach and to gain intuition about the many commonly used, modern, and powerful methods accepted in the machine learning community. If you are familiar with the analytic methodologies, this book may still serve as a reference for how to work with the various R packages for implementation.\nThis book is not meant to be an introduction to R or to programming in general; as we assume the reader has familiarity with the R language to include defining functions, managing R objects, controlling the flow of a program, and other basic tasks. If not, we would refer you to R for Data Science (Wickham and Grolemund 2016) to learn the fundamentals of data science with R such as importing, cleaning, transforming, visualizing, and exploring your data. For those looking to advance their R programming skills and knowledge of the language, we would refer you to Advanced R (Wickham 2014). Nor is this book designed to be a deep dive into the theory and math underpinning machine learning algorithms. Several books already exist that do great justice in this arena (i.e. Elements of Statistical Learning (Hastie, Tibshirani, and Friedman 2009), Computer Age Statistical Inference (Efron and Hastie 2016), Deep Learning (Goodfellow, Bengio, and Courville 2016)).\nInstead, this book is meant to help R users learn to use the machine learning stack within R, which includes using various R packages such as the tidymodels ecosystem of packages for model development, vip and pdp for model interpretation, TODO (add others as we develop) and others to effectively model and gain insight from your data. The book favors a hands-on approach, growing an intuitive understanding of machine learning through concrete examples and just a little bit of theory. While you can read this book without opening R, we highly recommend you experiment with the code examples provided throughout.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#why-r",
    "href": "index.html#why-r",
    "title": "Hands-On Machine Learning with R, 2ed",
    "section": "Why R",
    "text": "Why R\nIn this book we focus on implementing machine learning tasks with R. R has emerged over the last couple decades as a first-class tool for scientific computing tasks, and has been a consistent leader in implementing statistical methodologies for analyzing data. The usefulness of R for data science stems from the large, active, and growing ecosystem of third-party packages. We are not ignoring other languages such as Python or Julia because we think these tools are inferior. They’re not! And in practice, most organizations and data science teams use a mix of languages. In fact, throughout this book we may reference methods or implementations in other languages and we may even provide a few examples in Python. However, we strongly believe that it’s best to master one tool at a time, and R is a great place to start.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#conventions-used-in-this-book",
    "href": "index.html#conventions-used-in-this-book",
    "title": "Hands-On Machine Learning with R, 2ed",
    "section": "Conventions used in this book",
    "text": "Conventions used in this book\nThe following typographical conventions are used in this book:\n\nstrong italic: indicates new terms,\nbold: indicates package & file names,\ninline code: monospaced highlighted text indicates functions or other commands that could be typed literally by the user,\ncode chunk: indicates commands or other text that could be typed literally by the user\n\n\n1 + 2\n## [1] 3\n\nIn addition to the general text used throughout, you will notice the following code chunks with images:\n\n\n\n\n\n\nSignifies a tip or suggestion\n\n\n\n\n\n\n\n\n\nSignifies a general note\n\n\n\n\n\n\n\n\n\nSignifies a warning or caution",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#additional-resources",
    "href": "index.html#additional-resources",
    "title": "Hands-On Machine Learning with R, 2ed",
    "section": "Additional resources",
    "text": "Additional resources\nThere are many great resources available to learn about machine learning. Throughout the chapters we try to include many of the resources that we have found extremely useful for digging deeper into the methodology and applying with code. However, due to print restrictions, the hard copy version of this book limits the concepts and methods discussed. Online supplementary material exists at https://koalaverse.github.io/homlr/. The additional material will accumulate over time and include extended chapter material (i.e., random forest package benchmarking) along with brand new content we couldn’t fit in (i.e., random hyperparameter search). In addition, you can download the data used throughout the book, find teaching resources (i.e., slides and exercises), and more.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "Hands-On Machine Learning with R, 2ed",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nWe’d like to thank everyone who contributed feedback, typo corrections, and discussions while the book was being written. GitHub contributors included \\(@\\)agailloty, \\(@\\)asimumba, \\(@\\)benprew, \\(@\\)bfgray3, \\(@\\)bragks, \\(@\\)cunningjames, \\(@\\)DesmondChoy, \\(@\\)erickeniuk, \\(@\\)j-ryanhart, \\(@\\)lcreteig, \\(@\\)liangwu82, \\(@\\)Lianta, \\(@\\)mccurcio, \\(@\\)mmelcher76, \\(@\\)MMonterosso89, \\(@\\)nsharkey, \\(@\\)raycblai, \\(@\\)schoonees, \\(@\\)tpristavec and \\(@\\)william3031. We’d also like to thank folks such as Alex Gutman, Greg Anderson, Jay Cunningham, Joe Keller, Mike Pane, Scott Crawford, and several other co-workers who provided great input around much of this machine learning content.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#software-information",
    "href": "index.html#software-information",
    "title": "Hands-On Machine Learning with R, 2ed",
    "section": "Software information",
    "text": "Software information\nThis book was built with the following packages and R version. All code was executed on 2019 MacBook Pro with a 2.6 GHz 6-Core Intel Core i7 processor, 16 GB of memory, 2667 MHz speed, and double data rate synchronous dynamic random access memory (DDR4).\n\n# packages used\npkgs &lt;- c(\n    \"modeldata\",\n    \"tidymodels\",\n    \"vip\"\n)\n\n# package & session info\nsessioninfo::session_info(pkgs)\n#&gt; ─ Session info ───────────────────────────────────────────────────────────────\n#&gt;  setting  value\n#&gt;  version  R version 4.2.0 (2022-04-22)\n#&gt;  os       Ubuntu 24.04.2 LTS\n#&gt;  system   x86_64, linux-gnu\n#&gt;  ui       X11\n#&gt;  language (EN)\n#&gt;  collate  C.UTF-8\n#&gt;  ctype    C.UTF-8\n#&gt;  tz       UTC\n#&gt;  date     2025-04-02\n#&gt;  pandoc   3.1.3 @ /usr/bin/ (via rmarkdown)\n#&gt;  quarto   1.6.42 @ /usr/local/bin/quarto\n#&gt; \n#&gt; ─ Packages ───────────────────────────────────────────────────────────────────\n#&gt;  package      * version    date (UTC) lib source\n#&gt;  backports      1.5.0      2024-05-23 [1] CRAN (R 4.2.0)\n#&gt;  broom          1.0.8      2025-03-28 [1] CRAN (R 4.2.0)\n#&gt;  cachem         1.1.0      2024-05-16 [1] CRAN (R 4.2.0)\n#&gt;  class          7.3-20     2022-01-16 [3] CRAN (R 4.2.0)\n#&gt;  cli            3.6.4      2025-02-13 [1] CRAN (R 4.2.0)\n#&gt;  clock          0.7.3      2025-03-21 [1] CRAN (R 4.2.0)\n#&gt;  codetools      0.2-18     2020-11-04 [3] CRAN (R 4.2.0)\n#&gt;  colorspace     2.1-1      2024-07-26 [1] CRAN (R 4.2.0)\n#&gt;  conflicted     1.2.0      2023-02-01 [1] CRAN (R 4.2.0)\n#&gt;  cpp11          0.5.2      2025-03-03 [1] CRAN (R 4.2.0)\n#&gt;  data.table     1.17.0     2025-02-22 [1] CRAN (R 4.2.0)\n#&gt;  diagram        1.6.5      2020-09-30 [1] CRAN (R 4.2.0)\n#&gt;  dials          1.4.0      2025-02-13 [1] CRAN (R 4.2.0)\n#&gt;  DiceDesign     1.10       2023-12-07 [1] CRAN (R 4.2.0)\n#&gt;  digest         0.6.37     2024-08-19 [1] CRAN (R 4.2.0)\n#&gt;  doFuture       1.0.2      2025-03-16 [1] CRAN (R 4.2.0)\n#&gt;  dplyr          1.1.4      2023-11-17 [1] CRAN (R 4.2.0)\n#&gt;  fansi          1.0.6      2023-12-08 [1] CRAN (R 4.2.0)\n#&gt;  farver         2.1.2      2024-05-13 [1] CRAN (R 4.2.0)\n#&gt;  fastmap        1.2.0      2024-05-15 [1] CRAN (R 4.2.0)\n#&gt;  foreach        1.5.2      2022-02-02 [1] CRAN (R 4.2.0)\n#&gt;  furrr          0.3.1      2022-08-15 [1] CRAN (R 4.2.0)\n#&gt;  future         1.34.0     2024-07-29 [1] CRAN (R 4.2.0)\n#&gt;  future.apply   1.11.3     2024-10-27 [1] CRAN (R 4.2.0)\n#&gt;  generics       0.1.3      2022-07-05 [1] CRAN (R 4.2.0)\n#&gt;  ggplot2        3.5.1      2024-04-23 [1] CRAN (R 4.2.0)\n#&gt;  globals        0.16.3     2024-03-08 [1] CRAN (R 4.2.0)\n#&gt;  glue           1.8.0      2024-09-30 [1] CRAN (R 4.2.0)\n#&gt;  gower          1.0.2      2024-12-17 [1] CRAN (R 4.2.0)\n#&gt;  GPfit          1.0-8      2019-02-08 [1] CRAN (R 4.2.0)\n#&gt;  gtable         0.3.6      2024-10-25 [1] CRAN (R 4.2.0)\n#&gt;  hardhat        1.4.1      2025-01-31 [1] CRAN (R 4.2.0)\n#&gt;  infer          1.0.7      2024-03-25 [1] CRAN (R 4.2.0)\n#&gt;  ipred          0.9-15     2024-07-18 [1] CRAN (R 4.2.0)\n#&gt;  isoband        0.2.7      2022-12-20 [1] CRAN (R 4.2.0)\n#&gt;  iterators      1.0.14     2022-02-05 [1] CRAN (R 4.2.0)\n#&gt;  KernSmooth     2.23-20    2021-05-03 [3] CRAN (R 4.2.0)\n#&gt;  labeling       0.4.3      2023-08-29 [1] CRAN (R 4.2.0)\n#&gt;  lattice        0.20-45    2021-09-22 [3] CRAN (R 4.2.0)\n#&gt;  lava           1.8.1      2025-01-12 [1] CRAN (R 4.2.0)\n#&gt;  lhs            1.2.0      2024-06-30 [1] CRAN (R 4.2.0)\n#&gt;  lifecycle      1.0.4      2023-11-07 [1] CRAN (R 4.2.0)\n#&gt;  listenv        0.9.1      2024-01-29 [1] CRAN (R 4.2.0)\n#&gt;  lubridate      1.9.4      2024-12-08 [1] CRAN (R 4.2.0)\n#&gt;  magrittr       2.0.3      2022-03-30 [1] CRAN (R 4.2.0)\n#&gt;  MASS           7.3-56     2022-03-23 [3] CRAN (R 4.2.0)\n#&gt;  Matrix         1.4-1      2022-03-23 [3] CRAN (R 4.2.0)\n#&gt;  memoise        2.0.1      2021-11-26 [1] CRAN (R 4.2.0)\n#&gt;  mgcv           1.8-40     2022-03-29 [3] CRAN (R 4.2.0)\n#&gt;  modeldata      1.4.0      2024-06-19 [1] CRAN (R 4.2.0)\n#&gt;  modelenv       0.2.0      2024-10-14 [1] CRAN (R 4.2.0)\n#&gt;  munsell        0.5.1      2024-04-01 [1] CRAN (R 4.2.0)\n#&gt;  nlme           3.1-157    2022-03-25 [3] CRAN (R 4.2.0)\n#&gt;  nnet           7.3-17     2022-01-16 [3] CRAN (R 4.2.0)\n#&gt;  numDeriv       2016.8-1.1 2019-06-06 [1] CRAN (R 4.2.0)\n#&gt;  parallelly     1.43.0     2025-03-24 [1] CRAN (R 4.2.0)\n#&gt;  parsnip        1.3.1      2025-03-12 [1] CRAN (R 4.2.0)\n#&gt;  patchwork      1.3.0      2024-09-16 [1] CRAN (R 4.2.0)\n#&gt;  pillar         1.10.1     2025-01-07 [1] CRAN (R 4.2.0)\n#&gt;  pkgconfig      2.0.3      2019-09-22 [1] CRAN (R 4.2.0)\n#&gt;  prettyunits    1.2.0      2023-09-24 [1] CRAN (R 4.2.0)\n#&gt;  prodlim        2024.06.25 2024-06-24 [1] CRAN (R 4.2.0)\n#&gt;  progressr      0.15.1     2024-11-22 [1] CRAN (R 4.2.0)\n#&gt;  purrr          1.0.4      2025-02-05 [1] CRAN (R 4.2.0)\n#&gt;  R6             2.6.1      2025-02-15 [1] CRAN (R 4.2.0)\n#&gt;  RColorBrewer   1.1-3      2022-04-03 [1] CRAN (R 4.2.0)\n#&gt;  Rcpp           1.0.14     2025-01-12 [1] CRAN (R 4.2.0)\n#&gt;  recipes        1.2.1      2025-03-25 [1] CRAN (R 4.2.0)\n#&gt;  rlang          1.1.5      2025-01-17 [1] CRAN (R 4.2.0)\n#&gt;  rpart          4.1.16     2022-01-24 [3] CRAN (R 4.2.0)\n#&gt;  rsample        1.3.0      2025-04-02 [1] CRAN (R 4.2.0)\n#&gt;  rstudioapi     0.17.1     2024-10-22 [1] CRAN (R 4.2.0)\n#&gt;  scales         1.3.0      2023-11-28 [1] CRAN (R 4.2.0)\n#&gt;  sfd            0.1.0      2024-01-08 [1] CRAN (R 4.2.0)\n#&gt;  shape          1.4.6.1    2024-02-23 [1] CRAN (R 4.2.0)\n#&gt;  slider         0.3.2      2024-10-25 [1] CRAN (R 4.2.0)\n#&gt;  sparsevctrs    0.3.2      2025-03-21 [1] CRAN (R 4.2.0)\n#&gt;  SQUAREM        2021.1     2021-01-13 [1] CRAN (R 4.2.0)\n#&gt;  stringi        1.8.7      2025-03-27 [1] CRAN (R 4.2.0)\n#&gt;  stringr        1.5.1      2023-11-14 [1] CRAN (R 4.2.0)\n#&gt;  survival       3.3-1      2022-03-03 [3] CRAN (R 4.2.0)\n#&gt;  tibble         3.2.1      2023-03-20 [1] CRAN (R 4.2.0)\n#&gt;  tidymodels     1.3.0      2025-02-21 [1] CRAN (R 4.2.0)\n#&gt;  tidyr          1.3.1      2024-01-24 [1] CRAN (R 4.2.0)\n#&gt;  tidyselect     1.2.1      2024-03-11 [1] CRAN (R 4.2.0)\n#&gt;  timechange     0.3.0      2024-01-18 [1] CRAN (R 4.2.0)\n#&gt;  timeDate       4041.110   2024-09-22 [1] CRAN (R 4.2.0)\n#&gt;  tune           1.3.0      2025-02-21 [1] CRAN (R 4.2.0)\n#&gt;  tzdb           0.5.0      2025-03-15 [1] CRAN (R 4.2.0)\n#&gt;  utf8           1.2.4      2023-10-22 [1] CRAN (R 4.2.0)\n#&gt;  vctrs          0.6.5      2023-12-01 [1] CRAN (R 4.2.0)\n#&gt;  vip            0.4.1      2023-08-21 [1] CRAN (R 4.2.0)\n#&gt;  viridisLite    0.4.2      2023-05-02 [1] CRAN (R 4.2.0)\n#&gt;  warp           0.2.1      2023-11-02 [1] CRAN (R 4.2.0)\n#&gt;  withr          3.0.2      2024-10-28 [1] CRAN (R 4.2.0)\n#&gt;  workflows      1.2.0      2025-02-19 [1] CRAN (R 4.2.0)\n#&gt;  workflowsets   1.1.0      2024-03-21 [1] CRAN (R 4.2.0)\n#&gt;  yardstick      1.3.2      2025-01-22 [1] CRAN (R 4.2.0)\n#&gt; \n#&gt;  [1] /home/runner/work/_temp/Library\n#&gt;  [2] /opt/R/4.2.0/lib/R/site-library\n#&gt;  [3] /opt/R/4.2.0/lib/R/library\n#&gt; \n#&gt; ──────────────────────────────────────────────────────────────────────────────\n\n\n\n\n\nEfron, Bradley, and Trevor Hastie. 2016. Computer Age Statistical Inference. Vol. 5. Cambridge University Press.\n\n\nGoodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. Deep Learning. Vol. 1. MIT Press Cambridge.\n\n\nHastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. The Elements of Statistical Learning: Data Mining, Inference, and Prediction. Vol. 2. Springer Science+ Business Media.\n\n\nWickham, Hadley. 2014. Advanced r. CRC Press.\n\n\nWickham, Hadley, and Garrett Grolemund. 2016. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. O’Reilly Media, Inc.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "preface-2e.html",
    "href": "preface-2e.html",
    "title": "Preface to the second edition",
    "section": "",
    "text": "Welcome to the second edition of Hands-On Machine Learning with R! This is a major reworking of the first edition, removing material we no longer think is useful, adding material we wish we included in the first edition, and generally updating the text and code to reflect changes in best practices.\nA brief summary of the biggest changes follows:\n\nTBD\nTBD\nTBD",
    "crumbs": [
      "Preface to the second edition"
    ]
  },
  {
    "objectID": "01-intro.html",
    "href": "01-intro.html",
    "title": "1  Introduction to Machine Learning",
    "section": "",
    "text": "1.1 Supervised learning\nMachine learning (ML) continues to grow in importance for many organizations across nearly all domains. There’s no shortage of definitions for the term machine learning. For the purposes of this book, we can think of it as a blended field with a focus on using algorithms to help learn from data. This process of learning from data results in a model, which we can use to make predictions.\nSome example applications of machine learning in practice include:\nIn essence, these tasks all seek to learn and draw inferences from patterns in data. To address each scenario, we can use a given set of features to train an algorithm and extract insights. These algorithms, or learners, can be classified according to how they learn to make predictions and the four main groups of learners are:\nWhich type you will need to use depends on the learning task you hope to accomplish; and the primary focus of this book is on the first two groups of learners - supervised and unsupervised learning.\nSupervised learning is a set of ML learners that learn the relationship between inputs (often referred to as features or predictors) and output(s) (often referred to as the target variable). Or, as stated by Kuhn and Johnson (2013, 26:2), supervised learning is “…the process of developing a mathematical tool or model that generates an accurate prediction.” The learning algorithm in a supervised learning model attempts to discover and model the relationships among the target variable (the variable being predicted) and the other features. Examples of predictive modeling include the following:\nEach of these examples has a defined learning task; they each intend to use various features (\\(X\\)) to predict a well-defined target (\\(Y\\)). Think about the hospital readmission example. Predicting the liklihood of readmittance is not specific enough and will make pulling together relevant data a challenge, so we need to think carefully aabout how we define the features and response for modeling. Defining the target as whether or not a patient was readmitted within 30 days after release is something that can easily be measured, assuming it’s relevant to the stakeholders.\nThe scenarios listed above are examples of supervised learning. The supervision refers to the fact that the target values provide a supervisory role, which indicates to the learner the task it needs to learn. Specifically, given a set of data, the learning algorithm attempts to optimize a function (the algorithmic steps) to find the combination of feature values that results in a predicted value that is as close to the actual target output as possible.\nMost supervised learning problems can be bucketed into one of two general categories, regression or classification, depending on the type of response variable. We’ll briefly discuss both cases over the next two sections.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Machine Learning</span>"
    ]
  },
  {
    "objectID": "01-intro.html#supervised-learning",
    "href": "01-intro.html#supervised-learning",
    "title": "1  Introduction to Machine Learning",
    "section": "",
    "text": "Using customer attributes (e.g., age and recent shopping behavior) to predict the probability of the customer churning in the next 6 weeks.\nUsing various home attributes to predict the sales price.\nUsing employee attributes to predict the likelihood of attrition within the next six months.\nUsing patient attributes and symptoms to predict the risk of being readmitted to the hospital within 30 days after release.\nUsing product attributes to predict time to market.\nUsing weather conditions and relevant historical information to predict the number of bikes that will be rented out on a given day.\n\n\n\n\n\n\n\n\n\nIn supervised learning, the training data you feed the algorithm includes the target values. Consequently, the solutions can be used to help supervise the training process to find the optimal algorithm parameters, called hyperparameters.\n\n\n\n\n\n\n\n\n\n\nThroughout this text we’ll use various terms and notation interchangeably. In particular,\n\nwe’ll use \\(X\\) to denote a feature, predictor, or attribute (we may even use the more classic term independent variable);\nbold notation may be used to denote a set of features, for example \\(\\boldsymbol{X} = \\left(X_1, X_2\\right)\\), where, in the case of the predicting sale price example, \\(X_1\\) might represent square footage and \\(X_2\\) represent the overall quality of the home;\nwe’ll use \\(y\\) when referring to response or target variable (again, we may sometimes use the more classic term dependent variable).\n\n\n\n\n\n1.1.1 Regression problems\nWhen the objective is to predict a quantitative outcome, we generally refer to this as a regression problem (not to be confused with linear regression modeling, which is a special case). Regression problems revolve around numeric output where both order and distance matters (e.g., sales or a discrete count, like the number of bike rentals in a given day). In the examples above, predicting home sale prices based home attributes is a regression problem because the output is ordered and values closer to each other are closer in nature (e.g., the closer two sale prices are to each other the more similar the homes are in terms of sale value).\nFigure 1.1 shows a regression model’s predicted sale price of homes in Ames, Iowa (from 2006–2010) as a function of two attributes: year built and total square footage. Depending on the combination of these two features, the expected home sales price could fall anywhere along the surface.\n\n\n\n\n\n\n\n\nFigure 1.1: Average home sales price as a function of year built and total square footage.\n\n\n\n\nSee Table 1.1 for a few more examples of regression models:\n\n\n\nTable 1.1: Example regression problems\n\n\n\n\n\n\n\n\n\n\nScenario\nPotential features\nNumeric prediction\n\n\n\n\nPredict home prices\nSquare footage, zip code, number of bedrooms and bathrooms, lot size, mortgage interest rate, property tax rate, construction costs, and number of homes for sale in the area.\nThe home price in dollars.\n\n\nPredict ride time\nHistorical traffic conditions (gathered from smartphones, traffic sensors, ride-hailing and other navigation applications), distance from destination, and weather conditions.\nThe time in minutes and seconds to arrive at a destination.\n\n\nPredict loan interest rate\nCustomer credit score, number of loans outstanding, historical repayment history, size of loan requested, current inflation and treasury rates.\nThe interest rate to be applied to a loan.\n\n\n\n\n\n\nWe’ll learn various ways of building such a model in Part II of this book (TODO: cross-reference “Part II”).\n\n\n1.1.2 Classification problems\nWhen the objective of our supervised learning is to predict a qualitative (or categorical outcome), we refer to this generally as a classification problem. Classification problems most commonly revolve around predicting a binary or multinomial response measure such as:\n\nPredicting if a customer will redeem a coupon (coded as yes/no or 1/0)?\nPredicting if a customer will churn (coded as yes/no or 1/0)?\nPredicting if a customer will click on our online ad (coded as yes/no or 1/0)?\nPredicting if a customer review is:\n\nBinary: positive vs. negative.\nMultinomial: extremely negative to extremely positive on a 0–5 Likert scale.\n\n\n\n\n\n\n\n\n\n\nFigure 1.2: Classification problem modeling ‘Yes’/‘No’ response based on three features.\n\n\n\n\nHowever, when we apply ML models to classification problems, rather than predict a particular class (i.e., “yes” or “no”), we often want to predict the conditional probability of a particular class (i.e., yes: 0.65, no: 0.35).1 By default, the class with the highest predicted probability becomes the predicted class (called a classification). Consequently, even though we classify it as a classification problem (pun intended), we’re often still predicting a numeric output (i.e., a probability). However, the nature of the target variable is what makes it a classification problem.\nTable 1.2 illustrates some example classification predictions where the model predicts the conditional probability of “Yes” and “No” classes. A threshold of 0.5 probability is used to determine if the predicted class is “Yes” or “No”.\n\n\n\nTable 1.2: Example classification predictions\n\n\n\n\n\n\n\n\n\n\nPredicted “Yes” probability\nPredicted “No” probability\nPredicted class\n\n\n\n\n0.65\n0.35\nYes\n\n\n0.15\n0.85\nNo\n\n\n0.43\n0.57\nNo\n\n\n⋮\n⋮\n⋮\n\n\n0.72\n0.28\nYes\n\n\n\n\n\n\nThroughout this book we will commonly use the term classification for brevity; however, the distinction between predicting the probability of an output and classifying that prediction into a particular class is important and should not be overlooked. Frank Harrell’s discussion on classification versus prediction (Harrell 2017) is an excellent read to delve deeper into this distinction, along with why and when we should be focusing on probability prediction over classification and vice versa.\nAlthough there are ML algorithms that can be applied to regression problems but not classification and vice versa, most of the supervised learning algorithms we’ll cover in this book can be applied to both. These algorithms have become some of the most popular machine learning models in recent years (often driven by their availability in both proprietary and open-source software).\n\n\n1.1.3 Knowledge check\n\n\n\n\n\n\nIdentify the features, response variable, and the type of supervised model (regression or classification) required for the following tasks:\n\nThere is an online retailer that wants to predict whether you will click on a certain featured product given your demographics, the current products in your online basket, and the time since your previous purchase.\nA bank wants to use a customers historical data such as the number of loans they’ve had, the time it took to payoff those loans, previous loan defaults, the number of new loans within the past two years, along with the customers income and level of education to determine if they should issue them a new loan for a car.\nIf the bank above does issue a new loan, they want to use the same information to determine the interest rate of the new loan issued.\nTo better plan incoming and outgoing flights, an airline wants to use flight information such as scheduled flight time, day/month of year, number of passengers, airport departing from, airport arriving to, distance to travel, and weather warnings to determine if a flight will be delayed.\nWhat if the above airline wants to use the same information to predict the number of minutes a flight will arrive late or early?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Machine Learning</span>"
    ]
  },
  {
    "objectID": "01-intro.html#unsupervised-learning",
    "href": "01-intro.html#unsupervised-learning",
    "title": "1  Introduction to Machine Learning",
    "section": "1.2 Unsupervised learning",
    "text": "1.2 Unsupervised learning\nUnsupervised learning, in contrast to supervised learning, includes a set of statistical tools to better understand and describe your data, but performs the analysis without a target variable. In essence, unsupervised learning is concerned with identifying groups in a data set. The groups may be defined by the rows (i.e., clustering) or the columns (i.e., dimension reduction); however, the motive in each case is quite different.\nThe goal of clustering is to segment observations into similar groups based on the observed variables; for example, dividing consumers into different homogeneous groups, a process known as market segmentation.\nClustering differs from classification because the categories aren’t defined by you. For example, Figure 1.3 shows how an unsupervised model might cluster a weather dataset based on temperature, revealing segmentations that define the seasons. You would then have to name those clusters based on your understanding of the dataset.\n\n\n\n\n\n\n\n\n\n\n\n(a) Data containing similar weather patterns.\n\n\n\n\n\n\n\n\n\n\n\n(b) Clusters of weather patterns labeled as snow, sleet, rain, and no rain.\n\n\n\n\n\n\n\nFigure 1.3: Clustering weather patterns which we would label the clusters based on our understanding of the data.\n\n\n\nIn dimension reduction, we are often concerned with reducing the number of variables in a data set. For example, classical linear regression models break down in the presence of highly correlated features, a situation known as multicollinearity.2 Some dimension reduction techniques can be used to reduce the feature set to a potentially smaller set of uncorrelated variables. Such a reduced feature set is often used as input to downstream supervised learning models (e.g., principal component regression).\nUnsupervised learning is often performed as part of an exploratory data analysis (EDA). However, the exercise tends to be more subjective, and there is no simple goal for the analysis, such as prediction of a response. Furthermore, it can be hard to assess the quality of results obtained from unsupervised learning methods. The reason for this is simple. If we fit a predictive model using a supervised learning technique (e.g., linear regression), then it is possible to check our work by seeing how well our model predicts the response \\(y\\) on new observations not used in fitting the model. However, in unsupervised learning, there’s no way to check our work because we don’t know the true answer—the problem is unsupervised!\nDespite its subjectivity, the importance of unsupervised learning should not be overlooked and such techniques are often used in organizations to:\n\nDivide consumers into different homogeneous groups so that tailored marketing strategies can be developed and deployed for each segment.\nIdentify groups of online shoppers with similar browsing and purchase histories, as well as items that are of particular interest to the shoppers within each group. Then an individual shopper can be preferentially shown the items in which he or she is particularly likely to be interested, based on the purchase histories of similar shoppers.\nIdentify products that have similar purchasing behavior so that managers can manage them as product groups.\n\nThese questions, and many more, can be addressed with unsupervised learning. Moreover, the outputs of unsupervised learning models can be used as inputs to downstream supervised learning models.\n\n1.2.1 Knowledge check\n\n\n\n\n\n\nIdentify the type of unsupervised model required for the following tasks:\n\nSay you have a YouTube channel. You may have a lot of data about the subscribers of your channel. What if you want to use that data to detect groups of similar subscribers?\nSay you’d like to group Ohio counties together based on the demographics of their residents.\nA retailer has collected hundreds of attributes about all their customers; however, many of those features are highly correlated. They’d like to reduce the number of features down by combining all those highly correlated features into groups.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Machine Learning</span>"
    ]
  },
  {
    "objectID": "01-intro.html#reinforcement-learning",
    "href": "01-intro.html#reinforcement-learning",
    "title": "1  Introduction to Machine Learning",
    "section": "1.3 Reinforcement learning",
    "text": "1.3 Reinforcement learning\nReinforcement learning (RL) refers to a family of algorithms that learn to make predictions by getting rewards or penalties based on actions performed within an environment. A reinforcement learning system generates a policy that defines the best strategy for getting the most rewards.\nThis best strategy is learned through interactions with the environment and observations of how it responds. In the absence of a supervisor, the learner must independently discover the sequence of actions that maximize the reward. This discovery process is akin to a trial-and-error search. The quality of actions is measured by not just the immediate reward they return, but also the delayed reward they might fetch. As it can learn the actions that result in eventual success in an unseen environment without the help of a supervisor, reinforcement learning is a very powerful algorithm.\nA few examples of RL include:\n\nRobotics. Robots with pre-programmed behavior are useful in structured environments, such as the assembly line of an automobile manufacturing plant, where the task is repetitive in nature. However, in the unpredictable real world, where the interaction between a robot’s actions and the environment is uncertain, achieving precise pre-programmed actions becomes exceedingly challenging. In such situations, Reinforcement Learning (RL) offers an effective approach to develop versatile robots. RL has demonstrated success in the context of robotic path planning, where robots need to autonomously discover optimal, obstacle-free, and dynamically compatible paths between two locations.\nAlphaGo. Go, a Chinese board game dating back 3,000 years, stands out as one of the most intricate strategic games known. Its complexity is attributed to the staggering number of possible board configurations, estimated at 10^270, surpassing the complexity of chess by several orders of magnitude. In 2016, AlphaGo, an artificial intelligence agent based on Reinforcement Learning (RL), achieved victory against the world’s top human Go player. Much like a human player, AlphaGo learned through experience, engaging in thousands of games against professional opponents. Notably, the most recent RL-based Go agent possesses the unique ability to enhance its skills by playing against itself, a capability not available to human players.\nAutonomous Driving. An autonomous driving system faces the challenge of executing numerous perception and planning functions within an environment characterized by uncertainty. Reinforcement Learning (RL) is employed in various specific tasks, including vehicle path planning and motion prediction. Vehicle path planning entails the use of multiple low and high-level policies to make decisions that span different temporal and spatial scales. On the other hand, motion prediction involves the anticipation of pedestrian and other vehicle movements, thereby enabling an understanding of how the current environmental state might evolve.\n\nReinforcement learning as field has existed for quite some time but it really gained mainstream popularity after DeepMind’s break through application of Q-learning to play Atari games (Mnih et al. 2013). Since then reinforcement learning has experienced several major breakthroughs and gains in popularity. Unfortunately, this topic is beyond the scope of this book but we recommend Sutton and Barto (2018), Powell (2021), and Szepesvári (2022) to learn more about RL.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Machine Learning</span>"
    ]
  },
  {
    "objectID": "01-intro.html#generative-ai",
    "href": "01-intro.html#generative-ai",
    "title": "1  Introduction to Machine Learning",
    "section": "1.4 Generative AI",
    "text": "1.4 Generative AI\nGenerative AI represents a category of models that generate content based on user input. It possesses the capability to generate various forms of content, including original images, musical compositions, and humorous jokes. Additionally, it can summarize articles, provide instructions for performing tasks, or even enhance and modify photographs.\nGenerative AI is versatile in its ability to work with a wide range of inputs and produce diverse outputs, encompassing text, images, audio, and video. Furthermore, it can handle combinations of these input and output types. For instance, a model can take an image as input and generate both an image and accompanying text as output, or it can accept input in the form of an image and text and produce a video as the output.\nWe can discuss generative models by their inputs and outputs, typically written as “type of input”-to-“type of output.” For example, the following is a partial list of some inputs and outputs for generative models:\n\nText-to-text\nText-to-image\nText-to-video\nText-to-code\nText-to-speech\nImage and text-to-image\n\nTable 1.3 lists example use-cases of generative models.\n\n\n\nTable 1.3: Examples of generative models, their input, and an example of their possible output.\n\n\n\n\n\n\n\n\n\n\nModel\nInput\nExample output\n\n\n\n\nText-to-text\nWho came up with the michelin star rating for restaurants?\nThe Michelin star rating system for restaurants was introduced by the French tire company Michelin. The system was first developed in the early 20th century as a means to promote travel and, by extension, the use of automobiles, in order to increase the demand for tires. Michelin began publishing restaurant and hotel guides in 1900, and in 1926, they started awarding stars to restaurants in recognition of their culinary excellence. The Michelin Guide is highly regarded in the culinary world, and Michelin stars have become a prestigious mark of quality for restaurants. [source: ChatGPT ]\n\n\nText-to-image\nA brain riding a rocketship heading towards the moon.\n [source: Imagen ]\n\n\nText-to-code\nWrite a hello world statement in R\nprint(\"Hello, World!\") [source: Bard ]\n\n\nImage-to-text\n\nThis is a flamingo. They are found in the Caribbean. [Source: Google DeepMind]\n\n\n\n\n\n\nHow does generative AI work? At a high-level, generative models learn patterns in data with the goal to produce new but similar data. To produce unique and creative outputs, generative models are initially trained using an unsupervised approach, where the model learns to mimic the data it’s trained on. The model is sometimes trained further using supervised or reinforcement learning on specific data related to tasks the model might be asked to perform, for example, summarize an article or edit a photo.\nGenerative AI is a quickly evolving technology with new use cases constantly being discovered. For example, generative models are helping businesses refine their ecommerce product images by automatically removing distracting backgrounds or improving the quality of low-resolution images.\nAlthough this book does not delve into generative AI directly, the deep learning chapters do provide the foundation that many generative AI models are built upon.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Machine Learning</span>"
    ]
  },
  {
    "objectID": "01-intro.html#machine-learning-in",
    "href": "01-intro.html#machine-learning-in",
    "title": "1  Introduction to Machine Learning",
    "section": "1.5 Machine learning in ",
    "text": "1.5 Machine learning in \nThe ML open-source ecosystem is a vibrant and rapidly evolving collection of software tools, libraries, frameworks, and platforms that are made freely available to the public for building, training, and deploying ML. This ecosystem has played a crucial role in democratizing ML and making ML accessible to a wide range of data scientists, researchers, and organizations.\nAlthough this ecosystem expands multiple programming languages, our focus will predominately be with the R programming language. The R ecosystem provides a wide variety of ML algorithm implementations. This makes many powerful algorithms available at your fingertips. Moreover, there are almost always more than one package to perform each algorithm (e.g., there are over 20 packages for fitting random forests). There are pros and cons to this wide selection; some implementations may be more computationally efficient while others may be more flexible (i.e., have more hyperparameter tuning options).\nThis book will expose you to many of the R packages and algorithms that perform and scale best to the kinds of data and problems encountered by most organizations while also showing you how to use implementations that provide more consistency.\nFor example, more recently, development on a group of packages called Tidymodels has helped to make implementation easier. The tidymodels collection allows you to perform discrete parts of the ML workflow with discrete packages:\n\nrsample for data splitting and resampling\nrecipes for data pre-processing and feature engineering\nparsnip for applying algorithms\ntune for hyperparameter tuning\nyardstick for measuring model performance\nand several others!\n\n\n\n\n\n\n\nThe tidymodels package is a meta package, or a package of packages, that will install several packages that exist in the tidymodels ecosystem.\n\n\n\nThroughout this book you’ll be exposed to several of these packages and more. Moreover, in some cases, ML algorithms are available in one language but not another. As data scientists, we need to be comfortable in finding alternative solutions to those available in our native programming language of choice. Consequently, we may even provide examples of implementations using other languages such as Python or Julia.\nPrior to moving on, let’s take the time to make sure you have the required packages installed.\n\n\n\n\n\n\nTODO\n\n\n\nOnce book is complete provide link to DESCRIPTION file or alternative approach for an easy way for readers to install all requirements. Maybe discuss renv??\n\n\n\n# data wrangling\ninstall.packages(c(\"here\", \"tidyverse\"))\n\n# modeling\ninstall.packages(\"tidymodels\")\n\n# model interpretability\ninstall.packages(c(\"pdp\", \"vip\"))\n\n\npackageVersion(\"tidymodels\")\n## [1] '1.3.0'\n\nlibrary(tidymodels)\n## ── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n## ✔ broom        1.0.8     ✔ rsample      1.3.0\n## ✔ dials        1.4.0     ✔ tibble       3.2.1\n## ✔ dplyr        1.1.4     ✔ tidyr        1.3.1\n## ✔ infer        1.0.7     ✔ tune         1.3.0\n## ✔ modeldata    1.4.0     ✔ workflows    1.2.0\n## ✔ parsnip      1.3.1     ✔ workflowsets 1.1.0\n## ✔ purrr        1.0.4     ✔ yardstick    1.3.2\n## ✔ recipes      1.2.1\n## ── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n## ✖ purrr::discard() masks scales::discard()\n## ✖ dplyr::filter()  masks plotly::filter(), stats::filter()\n## ✖ dplyr::lag()     masks stats::lag()\n## ✖ recipes::step()  masks stats::step()\n\n\n1.5.1 Knowledge check\n\n\n\n\n\n\nCheck out the Tidymodels website: https://www.tidymodels.org/. Identify which packages can be used for:\n\nEfficiently splitting your data\nOptimizing hyperparameters\nMeasuring the effectiveness of your model\nWorking with correlation matrices",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Machine Learning</span>"
    ]
  },
  {
    "objectID": "01-intro.html#roadmap",
    "href": "01-intro.html#roadmap",
    "title": "1  Introduction to Machine Learning",
    "section": "1.6 Roadmap",
    "text": "1.6 Roadmap\nThe goal of this book is to provide effective methods and tools for uncovering relevant and useful patterns in your data by using R’s ML stack. We begin by providing an overview of the ML modeling process and discussing fundamental concepts that will carry through the rest of the book. These include feature engineering, data splitting, model validation and tuning, and assessing model performance. These concepts will be discussed more thoroughly in Chapters …\n\n\n\n\n\n\nTODO\n\n\n\nFill out roadmap as we progress",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Machine Learning</span>"
    ]
  },
  {
    "objectID": "01-intro.html#sec-data-intro",
    "href": "01-intro.html#sec-data-intro",
    "title": "1  Introduction to Machine Learning",
    "section": "1.7 Data sets",
    "text": "1.7 Data sets\n\n\n\n\n\n\nTODO\n\n\n\nRevisit as we progress",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Machine Learning</span>"
    ]
  },
  {
    "objectID": "01-intro.html#exercises",
    "href": "01-intro.html#exercises",
    "title": "1  Introduction to Machine Learning",
    "section": "1.8 Exercises",
    "text": "1.8 Exercises\n\nIdentify four real-life applications of supervised and unsupervised problems.\n\nExplain what makes these problems supervised versus unsupervised.\nFor each problem identify the target variable (if applicable) and potential features.\n\nIdentify and contrast a regression problem with a classification problem.\n\nWhat is the target variable in each problem and why would being able to accurately predict this target be beneficial to society?\nWhat are potential features and where could you collect this information?\nWhat is determining if the problem is a regression or a classification problem?\n\nIdentify three open source data sets suitable for ML (e.g., https://bit.ly/35wKu5c).\n\nExplain the type of ML models that could be constructed from the data (e.g., supervised versus unsupervised and regression versus classification).\nWhat are the dimensions of the data?\nIs there a code book that explains who collected the data, why it was originally collected, and what each variable represents?\nIf the data set is suitable for supervised learning, which variable(s) could be considered as a useful target? Which variable(s) could be considered as features?\n\nIdentify examples of misuse of ML in society. What was the ethical concern?\n\n\n\n\n\nHarrell, Frank. 2017. “Classification Vs. Prediction.” 2017. https://www.fharrell.com/post/classification/.\n\n\nKuhn, Max, and Kjell Johnson. 2013. Applied Predictive Modeling. Vol. 26. Springer.\n\n\nMnih, Volodymyr, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, and Martin A. Riedmiller. 2013. “Playing Atari with Deep Reinforcement Learning.” CoRR abs/1312.5602. http://arxiv.org/abs/1312.5602.\n\n\nPowell, Warren B. 2021. “From Reinforcement Learning to Optimal Control: A Unified Framework for Sequential Decisions.” In Handbook of Reinforcement Learning and Control, 29–74. Springer.\n\n\nSutton, Richard S, and Andrew G Barto. 2018. Reinforcement Learning: An Introduction. MIT press.\n\n\nSzepesvári, Csaba. 2022. Algorithms for Reinforcement Learning. Springer Nature.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Machine Learning</span>"
    ]
  },
  {
    "objectID": "01-intro.html#footnotes",
    "href": "01-intro.html#footnotes",
    "title": "1  Introduction to Machine Learning",
    "section": "",
    "text": "Conditional on the set of input feature values.↩︎\nTo be fair, and as we’ll see later in the book, the interpretation of most fitted ML models becomes problematic in the presence of correlated or (otherwise dependent) fetures.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Machine Learning</span>"
    ]
  },
  {
    "objectID": "02-modeling-process.html",
    "href": "02-modeling-process.html",
    "title": "2  First model with Tidymodels",
    "section": "",
    "text": "2.1 Prerequisites\nMuch like EDA, the ML process is very iterative and heuristic-based. With minimal knowledge of the problem or data at hand, it is difficult to know which ML method will perform best. This is known as the no free lunch theorem for ML (Wolpert 1996). Consequently, it is common for many ML approaches to be applied, evaluated, and modified before a final, optimal model can be determined. Performing this process correctly provides great confidence in our outcomes. If not, the results will be useless and, potentially, damaging 1.\nApproaching ML modeling correctly means approaching it strategically by spending our data wisely on learning and validation procedures, properly pre-processing the feature and target variables, minimizing data leakage, tuning hyperparameters, and assessing model performance. Many books and courses portray the modeling process as a short sprint. A better analogy would be a marathon where many iterations of these steps are repeated before eventually finding the final optimal model. This process is illustrated in Figure 2.1.\nBefore introducing specific algorithms, this chapter, and the next, introduce concepts that are fundamental to the ML modeling process and that you’ll see briskly covered in future modeling chapters. More specifically, this chapter is designed to get you acquainted with building predictive models using the Tidymodels construct. We’ll focus on the process of splitting our data for improved generalizability, using Tidymodel’s parsnip package for constructing our models, along with yardstick to measure model performance. Future chapters will build upon these concepts by focusing on other parts of the machine learning process illustrated above such as applying resampling procedures to give you a more robust assessment of model performance and performing hyperparameter tuning to control the complexity of machine learning algorithms.\nThis chapter leverages the following packages.\n# Helper packages\nlibrary(tidyverse)  # for data manipulation & plotting\n\n# Modeling process packages\nlibrary(modeldata)  # for accessing data\nlibrary(tidymodels) # for modeling procedures\nTo illustrate some of the concepts, we’ll use the Ames Housing and employee attrition data sets introduced in Section 1.7.\n# Ames housing data\names &lt;- modeldata::ames\n\n# Job attrition data\nattrition &lt;- modeldata::attrition %&gt;%\n   mutate(Attrition = fct_relevel(Attrition, \"Yes\"))",
    "crumbs": [
      "Supervised Learning",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>First model with Tidymodels</span>"
    ]
  },
  {
    "objectID": "02-modeling-process.html#splitting",
    "href": "02-modeling-process.html#splitting",
    "title": "2  First model with Tidymodels",
    "section": "2.2 Data splitting",
    "text": "2.2 Data splitting\nA major goal of the machine learning process is to find an algorithm \\(f\\left(X\\right)\\) that most accurately predicts future values (\\(\\hat{Y}\\)) based on a set of features (\\(X\\)). In other words, we want an algorithm that not only fits well to our past data, but more importantly, one that predicts a future outcome accurately. This is called the generalizability of our algorithm. How we “spend” our data will help us understand how well our algorithm generalizes to unseen data.\nTo provide an accurate understanding of the generalizability of our final optimal model, we can split our data into training and test data sets:\n\nTraining set: these data are used to develop feature sets, train our algorithms, tune hyperparameters, compare models, and all of the other activities required to choose a final model (e.g., the model we want to put into production).\nTest set: having chosen a final model, these data are used to estimate an unbiased assessment of the model’s performance, which we refer to as the generalization error.\n\n\n\n\n\n\n\nIt is critical that the test set not be used prior to selecting your final model. Assessing results on the test set prior to final model selection biases the model selection process since the testing data will have become part of the model development process.\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.2: Splitting data into training and test sets..\n\n\n\n\n\nGiven a fixed amount of data, typical recommendations for splitting your data into training-test splits include 60% (training)–40% (testing), 70%–30%, or 80%–20%. Generally speaking, these are appropriate guidelines to follow; however, it is good to keep the following points in mind:\n\nSpending too much in training (e.g., \\(&gt;80\\%\\)) won’t allow us to get a good assessment of predictive performance. We may find a model that fits the training data very well, but is not generalizable (overfitting).\nSometimes too much spent in testing (\\(&gt;40\\%\\)) won’t allow us to get a good assessment of model parameters.\n\nOther factors should also influence the allocation proportions. For example, very large training sets (e.g., \\(n &gt; 100\\texttt{K}\\)) often result in only marginal gains compared to smaller sample sizes. Consequently, you may use a smaller training sample to increase computation speed (e.g., models built on larger training sets often take longer to score new data sets in production). In contrast, as \\(p \\geq n\\) (where \\(p\\) represents the number of features), larger samples sizes are often required to identify consistent signals in the features.\nThe two most common ways of splitting data include simple random sampling and stratified sampling.\n\n2.2.1 Simple random sampling\nThe simplest way to split the data into training and test sets is to take a simple random sample. This does not control for any data attributes, such as the distribution of your response variable (\\(Y\\)).\n\n\n\n\n\n\nSampling is a random process so setting the random number generator with a common seed allows for reproducible results. Throughout this course we’ll often use the seed 123 for reproducibility but the number itself has no special meaning.\n\n\n\n\n# create train/test split\nset.seed(123)  # for reproducibility\nsplit  &lt;- initial_split(ames, prop = 0.7)\ntrain  &lt;- training(split)\ntest   &lt;- testing(split)\n\n# dimensions of training data\ndim(train)\n## [1] 2051   74\n\n# dimensions of test data\ndim(test)\n## [1] 879  74\n\nWith sufficient sample size, this sampling approach will typically result in a similar distribution of \\(Y\\) (e.g., Sale_Price in the ames data) between your training and test sets, as illustrated below.\n\ntrain %&gt;%\n  mutate(id = 'train') %&gt;%\n  bind_rows(test %&gt;% mutate(id = 'test')) %&gt;%\n  ggplot(aes(Sale_Price, color = id)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\n2.2.2 Stratified sampling\nIf we want to explicitly control the sampling so that our training and test sets have similar \\(Y\\) distributions, we can use stratified sampling. This is more common with classification problems where the response variable may be severely imbalanced (e.g., 90% of observations with response “Yes” and 10% with response “No”). However, we can also apply stratified sampling to regression problems for data sets that have a small sample size and where the response variable deviates strongly from normality (i.e., positively skewed like Sale_Price). With a continuous response variable, stratified sampling will segment \\(Y\\) into quantiles and randomly sample from each. Consequently, this will help ensure a balanced representation of the response distribution in both the training and test sets.\nTo perform stratified sampling we simply apply the strata argument in initial_split.\n\nset.seed(123)\nsplit_strat &lt;- initial_split(attrition, prop = 0.7, strata = \"Attrition\")\ntrain_strat &lt;- training(split_strat)\ntest_strat  &lt;- testing(split_strat)\n\nThe following illustrates that in our original employee attrition data we have an imbalanced response (No: 84%, Yes: 16%). By enforcing stratified sampling, both our training and testing sets have approximately equal response distributions.\n\n# original response distribution\ntable(attrition$Attrition) %&gt;% prop.table()\n## \n##       Yes        No \n## 0.1612245 0.8387755\n\n# response distribution for training data\ntable(train_strat$Attrition) %&gt;% prop.table()\n## \n##       Yes        No \n## 0.1605058 0.8394942\n\n# response distribution for test data\ntable(test_strat$Attrition) %&gt;% prop.table()\n## \n##       Yes        No \n## 0.1628959 0.8371041\n\n\n\n\n\n\n\nThere is very little downside to using stratified sampling so when trying to decide if you should use random sampling versus stratified sampling, error on the side of safety with stratified sampling.\n\n\n\n\n\n2.2.3 Class imbalances\nImbalanced data can have a significant impact on model predictions and performance (Kuhn and Johnson 2013). Most often this involves classification problems where one class has a very small proportion of observations (e.g., defaults - 5% versus nondefaults - 95%). Several sampling methods have been developed to help remedy class imbalance and most of them can be categorized as either up-sampling or down-sampling.\nDown-sampling balances the dataset by reducing the size of the abundant class(es) to match the frequencies in the least prevalent class. This method is used when the quantity of data is sufficient. By keeping all samples in the rare class and randomly selecting an equal number of samples in the abundant class, a balanced new dataset can be retrieved for further modeling. Furthermore, the reduced sample size reduces the computation burden imposed by further steps in the ML process.\nOn the contrary, up-sampling is used when the quantity of data is insufficient. It tries to balance the dataset by increasing the size of rarer samples. Rather than getting rid of abundant samples, new rare samples are generated by using repetition or bootstrapping (described further in ?sec-bootstrapping).\nNote that there is no absolute advantage of one sampling method over another. Application of these two methods depends on the use case it applies to and the data set itself. A combination of over- and under-sampling is often successful and a common approach is known as Synthetic Minority Over-Sampling Technique, or SMOTE (Chawla et al. 2002). This alternative sampling approach, as well as others, can be implemented in R with the themis package2, which provides additional sampling procedures on top of the rsample package.\n\n\n2.2.4 Knowledge check\n\n\n\n\n\n\n\nImport the penguins data from the modeldata package\nCreate a 70-30 stratified train-test split (species is the target variable).\nWhat are the response variable proportions for the train and test data sets?",
    "crumbs": [
      "Supervised Learning",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>First model with Tidymodels</span>"
    ]
  },
  {
    "objectID": "02-modeling-process.html#sec-building-models",
    "href": "02-modeling-process.html#sec-building-models",
    "title": "2  First model with Tidymodels",
    "section": "2.3 Building models",
    "text": "2.3 Building models\nThe R ecosystem provides a wide variety of ML algorithm implementations. This makes many powerful algorithms available at your fingertips. Moreover, there are almost always more than one package to perform each algorithm (e.g., there are over 20 packages for fitting random forests). There are pros and cons to this wide selection; some implementations may be more computationally efficient while others may be more flexible. This also has resulted in some drawbacks as there are inconsistencies in how algorithms allow you to define the formula of interest and how the results and predictions are supplied.\nFortunately, the tidymodels ecosystem simplifies this and, in particular, the parsnip package3 provides one common interface to train many different models supplied by other packages. Consequently, we’ll focus on building models the tidymodels way.\nTo create and fit a model with parsnip we follow 3 steps:\n\nCreate a model type\nChoose an “engine”\nFit our model\n\nLet’s illustrate by building a linear regression model. For our first model we will simply use two features from our training data - total square feet of the home (Gr_Liv_Area) and year built (Year_Built) to predict the sale price (Sale_Price).\n\n\n\n\n\n\nWe can use tidy() to get results of our model’s parameter estimates and their statistical properties. Although the summary() function can provide this output, it gives the results back in an unwieldy format. Go ahead, and run summary(lm_ols) to compare the results to what we see below.\nMany models have a tidy() method that provides the summary results in a more predictable and useful format (e.g. a data frame with standard column names)\n\n\n\n\nlm_ols &lt;- linear_reg() %&gt;%\n   fit(Sale_Price ~ Gr_Liv_Area + Year_Built, data = train)\n\ntidy(lm_ols)\n## # A tibble: 3 × 5\n##   term          estimate std.error statistic   p.value\n##   &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n## 1 (Intercept) -2157423.   69234.       -31.2 8.09e-175\n## 2 Gr_Liv_Area       94.4      2.12      44.4 2.54e-302\n## 3 Year_Built      1114.      35.5       31.4 5.30e-177\n\n\n\n\n\n\n\nDon’t worry about what these parameters mean at this point; we’ll cover these details in a future chapter.\n\n\n\nNow, you may have noticed that we only applied two of the three steps mentioned previously:\n\nCreate a model type\nChoose an “engine”\nFit our model\n\nThe reason is because most model objects (linear_reg() in this example) have a default engine. linear_reg() by default uses stats::lm for ordinary least squares.4 But we can always change the engine. For example, say you wanted to use keras to perform gradient descent linear regression, then you could change the engine to keras but use the same code workflow.\n\n\n\n\n\n\nFor this code to run successfully on your end you need to have the keras and tensorflow packages installed on your machine. Depending on your current setup this could be an easy process or you could run into problems. If you run into problems don’t fret, this is primarily just to illustrate how we can change engines.\n\n\n\n\nlm_sgd &lt;- linear_reg() %&gt;%\n   set_engine('keras') %&gt;%\n   fit(Sale_Price ~ Gr_Liv_Area + Year_Built, data = train)\n## Epoch 1/20\n## 65/65 - 0s - loss: 39843786752.0000 - 369ms/epoch - 6ms/step\n## Epoch 2/20\n## 65/65 - 0s - loss: 39656677376.0000 - 78ms/epoch - 1ms/step\n## Epoch 3/20\n## 65/65 - 0s - loss: 39485419520.0000 - 62ms/epoch - 952us/step\n## Epoch 4/20\n## 65/65 - 0s - loss: 39328112640.0000 - 64ms/epoch - 984us/step\n## Epoch 5/20\n## 65/65 - 0s - loss: 39184859136.0000 - 61ms/epoch - 943us/step\n## Epoch 6/20\n## 65/65 - 0s - loss: 39052500992.0000 - 62ms/epoch - 948us/step\n## Epoch 7/20\n## 65/65 - 0s - loss: 38931972096.0000 - 61ms/epoch - 941us/step\n## Epoch 8/20\n## 65/65 - 0s - loss: 38820270080.0000 - 61ms/epoch - 935us/step\n## Epoch 9/20\n## 65/65 - 0s - loss: 38716104704.0000 - 62ms/epoch - 955us/step\n## Epoch 10/20\n## 65/65 - 0s - loss: 38617149440.0000 - 61ms/epoch - 946us/step\n## Epoch 11/20\n## 65/65 - 0s - loss: 38521831424.0000 - 60ms/epoch - 928us/step\n## Epoch 12/20\n## 65/65 - 0s - loss: 38426841088.0000 - 61ms/epoch - 935us/step\n## Epoch 13/20\n## 65/65 - 0s - loss: 38330658816.0000 - 60ms/epoch - 930us/step\n## Epoch 14/20\n## 65/65 - 0s - loss: 38228471808.0000 - 62ms/epoch - 951us/step\n## Epoch 15/20\n## 65/65 - 0s - loss: 38116184064.0000 - 62ms/epoch - 949us/step\n## Epoch 16/20\n## 65/65 - 0s - loss: 37989974016.0000 - 61ms/epoch - 939us/step\n## Epoch 17/20\n## 65/65 - 0s - loss: 37845630976.0000 - 60ms/epoch - 930us/step\n## Epoch 18/20\n## 65/65 - 0s - loss: 37677907968.0000 - 60ms/epoch - 919us/step\n## Epoch 19/20\n## 65/65 - 0s - loss: 37483651072.0000 - 61ms/epoch - 940us/step\n## Epoch 20/20\n## 65/65 - 0s - loss: 37261320192.0000 - 60ms/epoch - 928us/step\n\n\n\n\n\n\n\nWhen we talk about ‘engines’ we’re really just referring to packages that provide the desired algorithm. Each model object has different engines available to use and they are all documented. For example check out the help file for linear_reg (?linear_reg) and you’ll see the different engines available (lm, brulee, glm, glmnet, etc.)\n\n\n\nThe beauty of this workflow is that if we want to explore different models we can simply change the model object. For example, say we wanted to run a K-nearest neighbor model. We can just use nearest_neighbor().\nIn this example we have pretty much the same code as above except we added the line of code set_mode(). This is because most algorithms require you to specify if you are building a regression model or a classification model.\n\n\n\n\n\n\nWhen you run this code you’ll probably get an error message saying that “This engine requires some package installs: ‘kknn’.” This just means you need to install.packages('kknn') and then you should be able to successfully run this code.\n\n\n\n\nknn &lt;- nearest_neighbor() %&gt;%\n   set_engine(\"kknn\") %&gt;%\n   set_mode(\"regression\") %&gt;%\n   fit(Sale_Price ~ Gr_Liv_Area + Year_Built, data = train)\n\n\n\n\n\n\n\nYou can see all the different model objects available at https://parsnip.tidymodels.org/reference/index.html\n\n\n\n\n2.3.1 Knowledge check\n\n\n\n\n\n\n\nIf you haven’t already done so, create a 70-30 stratified train-test split on the attrition data (note: Attrition is the response variable).\nUsing the logistic_reg() model object, fit a model using Age, DistanceFromHome, and JobLevel as the features.\nNow train a K-nearest neighbor model using the ‘kknn’ engine and be sure to set the mode to be a classification model.",
    "crumbs": [
      "Supervised Learning",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>First model with Tidymodels</span>"
    ]
  },
  {
    "objectID": "02-modeling-process.html#making-predictions",
    "href": "02-modeling-process.html#making-predictions",
    "title": "2  First model with Tidymodels",
    "section": "2.4 Making predictions",
    "text": "2.4 Making predictions\nWe have fit a few different models. Now, if we want to see our predictions we can simply apply predict() and feed it the data set we want to make predictions on. Here, we can see the predictions made on our training data for our ordinary least square linear regression model.\n\nlm_ols %&gt;% predict(train)\n## # A tibble: 2,051 × 1\n##      .pred\n##      &lt;dbl&gt;\n##  1 217657.\n##  2 214276.\n##  3 223425.\n##  4 260324.\n##  5 109338.\n##  6 195106.\n##  7 222217.\n##  8 126175.\n##  9  98550.\n## 10 120811.\n## # ℹ 2,041 more rows\n\nAnd here we get the predicted values for our KNN model.\n\nknn %&gt;% predict(train)\n## # A tibble: 2,051 × 1\n##      .pred\n##      &lt;dbl&gt;\n##  1 194967.\n##  2 192240 \n##  3 174220 \n##  4 269760 \n##  5 113617.\n##  6 173672 \n##  7 174820 \n##  8 120796 \n##  9 114560 \n## 10 121346 \n## # ℹ 2,041 more rows\n\nA similar process can be applied to make predictions for a classification model. For example, the following trains a classification model that predicts whether an employee will attrit based on their age. When we make predictions, the output is the predicted class (employee attrition is Yes or No).\n\nsimple_logit &lt;- logistic_reg() %&gt;%\n   fit(Attrition ~ Age, data = train_strat)\n\nsimple_logit %&gt;% predict(train_strat)\n## # A tibble: 1,028 × 1\n##    .pred_class\n##    &lt;fct&gt;      \n##  1 No         \n##  2 No         \n##  3 No         \n##  4 No         \n##  5 No         \n##  6 No         \n##  7 No         \n##  8 No         \n##  9 No         \n## 10 No         \n## # ℹ 1,018 more rows\n\nIn general, machine learning classifiers don’t just give binary predictions, but instead provide some numerical value between 0 and 1 for their predictions. This number, sometimes called the model score or confidence, is a way for the model to express their certainty about what class the input data belongs to. In most applications, the exact probability is ignored and we use a threshold (typically \\(\\geq 0.5\\)) to round the score to a binary answer, yes or no, employee attrition or not attrition. But in some cases we do want the prediction probabilities and we can get those by adding type = \"prob\" to our predict call.\n\nsimple_logit %&gt;% predict(train_strat, type = \"prob\")\n## # A tibble: 1,028 × 2\n##    .pred_Yes .pred_No\n##        &lt;dbl&gt;    &lt;dbl&gt;\n##  1    0.178     0.822\n##  2    0.0485    0.952\n##  3    0.204     0.796\n##  4    0.155     0.845\n##  5    0.162     0.838\n##  6    0.213     0.787\n##  7    0.195     0.805\n##  8    0.213     0.787\n##  9    0.0664    0.934\n## 10    0.141     0.859\n## # ℹ 1,018 more rows\n\n\n2.4.1 Knowledge check\n\n\n\n\n\n\n\nUsing the logistic regression model you trained in the previous exercise, make predictions on the attrition training data.\nNow make predictions using the K-nearest neighbor model.",
    "crumbs": [
      "Supervised Learning",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>First model with Tidymodels</span>"
    ]
  },
  {
    "objectID": "02-modeling-process.html#sec-model-eval",
    "href": "02-modeling-process.html#sec-model-eval",
    "title": "2  First model with Tidymodels",
    "section": "2.5 Model evaluation",
    "text": "2.5 Model evaluation\nHistorically, the performance of statistical models was largely based on goodness-of-fit tests and assessment of residuals. Unfortunately, misleading conclusions may follow from predictive models that pass these kinds of assessments (Breiman et al. 2001). Today, it has become widely accepted that a more sound approach to assessing model performance is to assess the predictive accuracy via loss functions. Loss functions are metrics that compare the predicted values to the actual value (the output of a loss function is often referred to as the error or pseudo residual).\nIf we look at our predicted outputs for our ordinary least squares model, we can see that the predicted home value (.pred) was $149,091 for the first observation and the actual home value was $172,000, resulting in an error of nearly $23,000. The objective of the loss function is to aggregate the prediction errors for all the observations into a meaningful single value metric.\n\nlm_ols %&gt;%\n   predict(test) %&gt;%\n   bind_cols(test %&gt;% select(Sale_Price)) %&gt;%\n   mutate(prediction_error = Sale_Price - .pred)\n## # A tibble: 879 × 3\n##      .pred Sale_Price prediction_error\n##      &lt;dbl&gt;      &lt;int&gt;            &lt;dbl&gt;\n##  1 149091.     172000           22909.\n##  2 219596.     195500          -24096.\n##  3 195491.     212000           16509.\n##  4  97418.     141000           43582.\n##  5 152195.     170000           17805.\n##  6 134471.     142000            7529.\n##  7 119697.     115000           -4697.\n##  8 195517.     184000          -11517.\n##  9 141210.      88000          -53210.\n## 10 239057.     306000           66943.\n## # ℹ 869 more rows\n\nThere are many loss functions to choose from when assessing the performance of a predictive model, each providing a unique understanding of the predictive accuracy and differing between regression and classification models. Furthermore, the way a loss function is computed will tend to emphasize certain types of errors over others and can lead to drastic differences in how we interpret the “optimal model”. Its important to consider the problem context when identifying the preferred performance metric to use. And when comparing multiple models, we need to compare them across the same metric.\n\n2.5.1 Regression models\nThe most common loss functions for regression models include:\n\nMSE: Mean squared error is the average of the squared error (\\(MSE = \\frac{1}{n} \\sum^n_{i=1}(y_i - \\hat y_i)^2\\))5. The squared component results in larger errors having larger penalties. Objective: minimize\nRMSE: Root mean squared error. This simply takes the square root of the MSE metric (\\(RMSE = \\sqrt{\\frac{1}{n} \\sum^n_{i=1}(y_i - \\hat y_i)^2}\\)) so that your error is in the same units as your response variable. If your response variable units are dollars, the units of MSE are dollars-squared, but the RMSE will be in dollars. Objective: minimize\n\\(R^2\\): This is a popular metric that represents the proportion of the variance in the dependent variable that is predictable from the independent variable(s). Unfortunately, it has several limitations. For example, two models built from two different data sets could have the exact same RMSE but if one has less variability in the response variable then it would have a lower \\(R^2\\) than the other. You should not place too much emphasis on this metric. Objective: maximize\n\nLet’s compute the RMSE of our OLS regression model. Remember, we want to assess our model’s performance on the test data not the training data since that gives us a better idea of how our model generalizes. To do so, the following:\n\nMakes predictions with our test data,\nAdds the actual Sale_Price values from our test data,\nComputes the RMSE.\n\n\nlm_ols %&gt;%\n   predict(test) %&gt;%\n   bind_cols(test %&gt;% select(Sale_Price)) %&gt;%\n   rmse(truth = Sale_Price, estimate = .pred)\n## # A tibble: 1 × 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 rmse    standard      45445.\n\nThe RMSE value suggests that, on average, our model mispredicts the expected sale price of a home by about $45K.\nOther common loss functions for regression models include:\n\nDeviance: Short for mean residual deviance. In essence, it provides a degree to which a model explains the variation in a set of data when using maximum likelihood estimation. Essentially this compares a saturated model (i.e. fully featured model) to an unsaturated model (i.e. intercept only or average). If the response variable distribution is Gaussian, then it will be approximately equal to MSE. When not, it usually gives a more useful estimate of error. Deviance is often used with classification models. 6 Objective: minimize\nMAE: Mean absolute error. Similar to MSE but rather than squaring, it just takes the mean absolute difference between the actual and predicted values (\\(MAE = \\frac{1}{n} \\sum^n_{i=1}(\\vert y_i - \\hat y_i \\vert)\\)). This results in less emphasis on larger errors than MSE. Objective: minimize\nRMSLE: Root mean squared logarithmic error. Similar to RMSE but it performs a log() on the actual and predicted values prior to computing the difference (\\(RMSLE = \\sqrt{\\frac{1}{n} \\sum^n_{i=1}(log(y_i + 1) - log(\\hat y_i + 1))^2}\\)). When your response variable has a wide range of values, large response values with large errors can dominate the MSE/RMSE metric. RMSLE minimizes this impact so that small response values with large errors can have just as meaningful of an impact as large response values with large errors. Objective: minimize\n\n\n\n2.5.2 Classification models\nWhen applying classification models, we often use a confusion matrix to evaluate certain performance measures. A confusion matrix is simply a matrix that compares actual categorical levels (or events) to the predicted categorical levels. When we predict the right level, we refer to this as a true positive. However, if we predict a level or event that did not happen this is called a false positive (i.e. we predicted a customer would redeem a coupon and they did not). Alternatively, when we do not predict a level or event and it does happen that this is called a false negative (i.e. a customer that we did not predict to redeem a coupon does).\n\n\n\n\n\n\n\n\nFigure 2.3: Confusion matrix and relationships to terms such as true-positive and false-negative.\n\n\n\n\n\nLet’s go ahead and create a logistic regression classification model with the attrition data.\n\n\n\n\n\n\nIn R, using a “.”” as in Attrition ~ . is a shortcut for saying use all available features to predict Attrition.\n\n\n\n\nlogit &lt;- logistic_reg() %&gt;%\n   fit(Attrition ~ ., data = train_strat)\n\nWe can use conf_mat() to view the confusion matrix for this model. In essence, this confusion matrix shows that our model has 34 true positive predictions, 353 true negative predictions, 17 false negative predictions, and 38 false predictions.\n\nlogit %&gt;%\n   predict(test_strat) %&gt;%\n   bind_cols(test_strat %&gt;% select(Attrition)) %&gt;%\n   conf_mat(truth = Attrition, estimate = .pred_class, dnn = c(\"Truth\", \"Prediction\"))\n##      Prediction\n## Truth Yes  No\n##   Yes  34  17\n##   No   38 353\n\n\n\n\n\n\n\nDepending on the software and libraries used, you may see the prediction summaries on the rows and the actual value summaries in the columns or vice versa. conf_mat allows us to control that with the dnn argument to control the table dimension names.\n\n\n\nThis confusion matrix allows us to extract different levels of performance for our classification model. For example, we can assess:\n\nAccuracy: Overall, how often is the classifier correct? Accuracy is the proportion of the data that are predicted correctly. Example: \\(\\frac{TP + TN}{total} = \\frac{34+353}{442} = 0.867\\). Objective: maximize\nPrecision: How accurately does the classifier predict events (or positive events)? This metric is concerned with maximizing the true positives to false positive ratio. In other words, for the number of predictions that we made, how many were correct? This characterizes the “purity in retrieval performance” (Buckland and Gey 1994). Example: \\(\\frac{TP}{TP + FP} = \\frac{34}{34+17} = 0.667\\). Objective: maximize\nSensitivity (aka recall): How accurately does the classifier classify actual events? The sensitivity is defined as the proportion of positive results out of the number of samples which were actually positive. This metric is concerned with maximizing the true positives to false negatives ratio. In other words, for the events that occurred, how many did we predict? Example: \\(\\frac{TP}{TP + FN} = \\frac{34}{34+38} = 0.472\\). Objective: maximize\nSpecificity: How accurately does the classifier classify actual non-events? The specificity measures the proportion of negatives that are correctly identified as negatives. Example: \\(\\frac{TN}{TN + FP} = \\frac{353}{353+17} = 0.954\\). Objective: maximize\n\n\npredict_and_actuals &lt;- logit %&gt;%\n   predict(test_strat) %&gt;%\n   bind_cols(test_strat %&gt;% select(Attrition))\n\n# accuracy\npredict_and_actuals %&gt;% accuracy(truth = Attrition, estimate = .pred_class)\n## # A tibble: 1 × 3\n##   .metric  .estimator .estimate\n##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n## 1 accuracy binary         0.876\n\n# precision\npredict_and_actuals %&gt;% precision(truth = Attrition, estimate = .pred_class)\n## # A tibble: 1 × 3\n##   .metric   .estimator .estimate\n##   &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n## 1 precision binary         0.667\n\n# recall\npredict_and_actuals %&gt;% sensitivity(truth = Attrition, estimate = .pred_class)\n## # A tibble: 1 × 3\n##   .metric     .estimator .estimate\n##   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n## 1 sensitivity binary         0.472\n\n# specificity\npredict_and_actuals %&gt;% specificity(truth = Attrition, estimate = .pred_class)\n## # A tibble: 1 × 3\n##   .metric     .estimator .estimate\n##   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n## 1 specificity binary         0.954\n\nOur results show that our model has high accuracy, which is mainly driven by our model’s ability to predict non-events (employees that do not attrit) accurately. However, our model does not do a very good job of predicting positive events (employees that do attrit), represented by the low precision and sensitivity values.\nA good binary classifier will have high precision and sensitivity. This means the classifier does well when it predicts an event will and will not occur, which minimizes false positives and false negatives. To capture this balance, we often use a receiver operator curve (ROC) that plots the sensitivity on the y-axis and 1-specificity on the x-axis. A line that is diagonal from the lower left corner to the upper right corner represents a random guess. The higher the line is in the upper left-hand corner, the better.\n\n\n\n\n\n\n\n\nFigure 2.4: ROC curve.\n\n\n\n\n\nTo plot the ROC curve we actually need to predict the probability of our classification model’s prediction. We then pass the predicted probabilities for the class we care about (here we are concerned with the probability of employees actually attriting) and the truth values to roc_curve.\n\nlogit %&gt;%\n   predict(test_strat, type = \"prob\") %&gt;%\n   bind_cols(test_strat %&gt;% select(Attrition)) %&gt;%\n   roc_curve(truth = Attrition, .pred_Yes) %&gt;%\n   autoplot()\n\n\n\n\n\n\n\n\nAnother common metric is the area under the curve (AUC). Generally, an ROC AUC value is between 0.5 and 1, with 1 being a perfect prediction model. If your value is between 0 and 0.5, then this implies that you have meaningful information in your model, but it is being applied incorrectly because doing the opposite of what the model predicts would result in an AUC &gt; 0.5. The benefit of the AUC metric is that it gives us a single metric value that incorporates both sensitivity and specificity of our model. The higher the AUC value, the more balanced our model is.\n\nlogit %&gt;%\n   predict(test_strat, type = \"prob\") %&gt;%\n   bind_cols(test_strat %&gt;% select(Attrition)) %&gt;%\n   roc_auc(truth = Attrition, .pred_Yes)\n## # A tibble: 1 × 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 roc_auc binary         0.835\n\n\n\n2.5.3 Knowledge check\n\n\n\n\n\n\n\nCompute and compare the \\(R^2\\) of the lm_ols and knn models trained in Section 2.3.\nNow compute the accuracy rate and AUC of the simple_logit model trained in Section 2.3 and compare it to the logit model trained in Section 2.5.2.",
    "crumbs": [
      "Supervised Learning",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>First model with Tidymodels</span>"
    ]
  },
  {
    "objectID": "02-modeling-process.html#exercises",
    "href": "02-modeling-process.html#exercises",
    "title": "2  First model with Tidymodels",
    "section": "2.6 Exercises",
    "text": "2.6 Exercises\n\n\n\n\n\n\nFor this exercise use the Chicago ridership data set provided by the modeldata library.7. This data set is derived from Kuhn and Johnson (2019) and contains an abbreviated training set for modeling the number of people (in thousands) who enter the Clark and Lake L station. The objective is to use the available features (i.e. temp (temparature), wind (wind speed), Bulls_Home (is there a Chicago Bulls game at home), etc. to predict the the number of people (in thousands) represented by the ridership column.\nModeling tasks:\n\nLoad the Chicago ridership data set and remove the date column.\nSplit the data into a training set and test set using a 70-30% split.\nHow many observations are in the training set and test set?\nCompare the distribution of ridership between the training set and test set.\nFit a linear regression model using all available features to predict ridership and compute the RMSE on the test data.\nFit a K-nearest neighbor model that uses all available features to predict ridership and compute the RMSE on the test data.\nHow do these models compare?\n\n\n\n\n\n\n\n\nBreiman, Leo et al. 2001. “Statistical Modeling: The Two Cultures (with Comments and a Rejoinder by the Author).” Statistical Science 16 (3): 199–231.\n\n\nBuckland, Michael, and Fredric Gey. 1994. “The Relationship Between Recall and Precision.” Journal of the American Society for Information Science 45 (1): 12–19.\n\n\nChawla, Nitesh V, Kevin W Bowyer, Lawrence O Hall, and W Philip Kegelmeyer. 2002. “SMOTE: Synthetic Minority over-Sampling Technique.” Journal of Artificial Intelligence Research 16: 321–57.\n\n\nKuhn, Max, and Kjell Johnson. 2013. Applied Predictive Modeling. Vol. 26. Springer.\n\n\n———. 2019. Feature Engineering and Selection: A Practical Approach for Predictive Models. Chapman; Hall/CRC.\n\n\nWolpert, David H. 1996. “The Lack of a Priori Distinctions Between Learning Algorithms.” Neural Computation 8 (7): 1341–90.",
    "crumbs": [
      "Supervised Learning",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>First model with Tidymodels</span>"
    ]
  },
  {
    "objectID": "02-modeling-process.html#footnotes",
    "href": "02-modeling-process.html#footnotes",
    "title": "2  First model with Tidymodels",
    "section": "",
    "text": "See https://www.fatml.org/resources/relevant-scholarship for many discussions regarding implications of poorly applied and interpreted ML.↩︎\nhttps://themis.tidymodels.org↩︎\nhttps://parsnip.tidymodels.org↩︎\nlm() is the built in function provided by R to perform ordinary least squares regression. You can learn more about it by checking out the help docs with ?lm.↩︎\nThis deviates slightly from the usual definition of MSE in ordinary linear regression, where we divide by \\(n-p\\) (to adjust for bias) as opposed to \\(n\\).↩︎\nSee this StackExchange thread (http://bit.ly/what-is-deviance) for a good overview of deviance for different models and in the context of regression versus classification.↩︎\nSee more details at https://modeldata.tidymodels.org/reference/Chicago.html↩︎",
    "crumbs": [
      "Supervised Learning",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>First model with Tidymodels</span>"
    ]
  },
  {
    "objectID": "03-slr.html",
    "href": "03-slr.html",
    "title": "3  Linear regression",
    "section": "",
    "text": "3.1 Prerequisites\nLinear regression, a staple of classical statistical modeling, is one of the simplest algorithms for doing supervised learning. Though it may seem somewhat dull compared to some of the more modern statistical learning approaches described in later chapters, linear regression is still a useful and widely applied statistical learning method. Moreover, it serves as a good starting point for more advanced approaches; as we will see in later chapters, many of the more sophisticated statistical learning approaches can be seen as generalizations to or extensions of ordinary linear regression. Consequently, it is important to have a good understanding of linear regression before studying more complex learning methods.\nThis chapter leverages the following packages:\n# Data wrangling & visualization packages\nlibrary(tidyverse)\n\n# Modeling packages\nlibrary(tidymodels)\nWe’ll also continue working with the Ames housing data:\n# stratified sampling with the rsample package\names &lt;- AmesHousing::make_ames()\n\nset.seed(123)\nsplit  &lt;- initial_split(ames, prop = 0.7, strata = \"Sale_Price\")\names_train  &lt;- training(split)\names_test   &lt;- testing(split)",
    "crumbs": [
      "Supervised Learning",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Linear regression</span>"
    ]
  },
  {
    "objectID": "03-slr.html#correlation",
    "href": "03-slr.html#correlation",
    "title": "3  Linear regression",
    "section": "3.2 Correlation",
    "text": "3.2 Correlation\nCorrelation is a single-number statistic that measures the extent that two variables are related (“co-related”) to one another. For example, say we want to understand the relationship between the total above ground living space of a home (Gr_Liv_Area) and the home’s sale price (Sale_Price).\nLooking at the following scatter plot we can see that some relationship does exist. It appears that as Gr_Liv_Area increases the Sale_Price of a home increases as well.\n\nggplot(ames_train, aes(Gr_Liv_Area, Sale_Price)) +\n   geom_point(size = 1.5, alpha = .25)\n\n\n\n\n\n\n\n\nCorrelation allows us to quantify this relationship. We can compute the correlation with the following:\n\names_train %&gt;%\n   summarize(correlation = cor(Gr_Liv_Area, Sale_Price))\n## # A tibble: 1 × 1\n##   correlation\n##         &lt;dbl&gt;\n## 1       0.708\n\nThe value of a correlation coefficient will always vary between +1 and -1. In our example, the correlation coefficient is 0.71. When the value of the correlation coefficient is +1 or -1, then it is said to be a perfect degree of association between the two variables (near +1 implies a strong positive association and near -1 implies a strong negative association). This simply means that when there is a one unit change in one variable we will always see a certain change change in units in the other variable. As the correlation coefficient nears 0, the relationship between the two variables weakens with a near 0 value implying no association between the two variables (a one unit change in one variable has no relationship to any level of change in the other variable).\nSo, in our case we could say we have a moderate positive correlation between Gr_Liv_Area and Sale_Price. Let’s look at another relationship. In the following we look at the relationship between the unfinished basement square footage of homes (Bsmt_Unf_SF) and the Sale_Price.\n\nggplot(ames_train, aes(Bsmt_Unf_SF, Sale_Price)) +\n   geom_point(size = 1.5, alpha = .25)\n\n\n\n\n\n\n\n\nIn this example, we don’t see much of a relationship. Basically, as Bsmt_Unf_SF gets larger or smaller, we really don’t see a strong pattern with Sale_Price.\nIf we look at the correlation for this relationship, we see that the correlation coefficient is much closer to zero than to 1. This confirms our visual assessment that there does not seem to be much of a relationship between these two variables.\n\names_train %&gt;%\n   summarize(correlation = cor(Bsmt_Unf_SF, Sale_Price))\n## # A tibble: 1 × 1\n##   correlation\n##         &lt;dbl&gt;\n## 1       0.186\n\nAlthough a useful measure, correlation can be hard to imagine exactly what the association is between two variables based on this single statistic. Moreover, its important to realize that correlation typically assumes a linear relationship between two variables.\nFor example, let’s check out the anscombe data, which is a built-in data set provided in R. If we look at each x and y relationship visually, we can see significant differences:\n\np1 &lt;- qplot(x = x1, y = y1, data = anscombe)\np2 &lt;- qplot(x = x2, y = y2, data = anscombe)\np3 &lt;- qplot(x = x3, y = y3, data = anscombe)\np4 &lt;- qplot(x = x4, y = y4, data = anscombe)\n\ngridExtra::grid.arrange(p1, p2, p3, p4, ncol = 2)\n\n\n\n\n\n\n\n\nHowever, if we compute the correlation between each of these relationships we see that they all have nearly equal correlation coefficients!\n\n\n\n\n\n\nNever take a correlation coefficient at face value! You should always compare the visual relationship with the computed correlation value.\n\n\n\n\nanscombe %&gt;%\n   summarize(\n      corr_x1_y1 = cor(x1, y1),\n      corr_x2_y2 = cor(x2, y2),\n      corr_x3_y3 = cor(x3, y3),\n      corr_x4_y4 = cor(x4, y4)\n      )\n##   corr_x1_y1 corr_x2_y2 corr_x3_y3 corr_x4_y4\n## 1  0.8164205  0.8162365  0.8162867  0.8165214\n\nThere are actually several different ways to measure correlation. The most common, and the one we’ve been using here, is Pearson’s correlation, represented by \\(r_{xy}\\). Given paired data \\(\\left\\{(x_{1},y_{1}),\\ldots ,(x_{n},y_{n})\\right\\}\\) consisting of \\(n\\) pairs, \\(r_{xy}\\) is defined as\n\\[\nr_{XY}={\\frac {\\sum_{i=1}^{n}(X_i-{\\bar {X}})(Y_i-{\\bar {Y}})}{{\\sqrt {\\sum_{i=1}^{n}(X_i-{\\bar {X}})^{2}}}{\\sqrt {\\sum_{i=1}^{n}(Y_i-{\\bar {Y}})^{2}}}}}\n\\]\nwhere \\(X_i\\) and \\(Y_i\\) represent the individual sample points and \\(\\bar{X}\\) and \\(\\bar{Y}\\) are the sample mean. There are alternative methods that allow us to loosen some assumptions such as assuming a linear relationship; however, in the next section we’ll see how simple linear regression fully characterizes this Pearson’s correlation.\n\n3.2.1 Knowledge check\n\n\n\n\n\n\n\nInterpreting coefficients that are not close to the extreme values of -1, 0, and 1 can be somewhat subjective. To help develop your sense of correlation coefficients, we suggest you play the 80s-style video game called, “Guess the Correlation”, at http://guessthecorrelation.com/\nUsing the ames_train data, visualize the relationship between Year_Built and Sale_Price.\nGuess what the correlation is between these two variables?\nNow compute the correlation between these two variables.",
    "crumbs": [
      "Supervised Learning",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Linear regression</span>"
    ]
  },
  {
    "objectID": "03-slr.html#simple-linear-regression",
    "href": "03-slr.html#simple-linear-regression",
    "title": "3  Linear regression",
    "section": "3.3 Simple linear regression",
    "text": "3.3 Simple linear regression\nAs discussed in the last section, correlation is often used to quantify the strength of the linear association between two continuous variables. However, this statistic alone does not provide us with a lot of actionable insights. But we can build on the concept of correlation to provide us with more useful information.\nIn this section, we seek to fully characterize the linear relationship we measured with correlation using a method called simple linear regression (SLR).\n\n3.3.1 Best fit line\nLet’s go back to our plot illustrating the relationship between Gr_Liv_Area and Sale_Price. We can characterize this relationship with a linear line that we consider is the “best-fitting” line (we’ll define “best-fitting” in a little bit). We do this by adding overplotting with geom_smooth(method = \"lm\", se = FALSE)\n\nggplot(ames_train, aes(Gr_Liv_Area, Sale_Price)) +\n   geom_point(size = 1.5, alpha = .25) +\n   geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n\n\n\nThe line in the above plot is called a “regression line.” The regression line is a visual summary of the linear relationship between two numerical variables, in our case the outcome variable Sale_Price and the explanatory variable Gr_Liv_Area. The positive slope of the blue line is consistent with our earlier observed correlation coefficient of 0.71 suggesting that there is a positive relationship between these two variables.\nMathematically, we can express this regression line as\n\\[\nY_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i, \\quad \\text{for } i = 1, 2, \\dots, n,\n\\tag{3.1}\\]\nwhere \\(Y_i\\) represents the i-th response value, \\(X_i\\) represents the i-th feature value, \\(\\beta_0\\) and \\(\\beta_1\\) are fixed, but unknown constants (commonly referred to as coefficients or parameters) that represent the intercept and slope of the regression line, respectively, and \\(\\epsilon_i\\) represents noise or random error. In this chapter, we’ll assume that the errors are normally distributed with mean zero and constant variance \\(\\sigma^2\\), denoted \\(\\stackrel{iid}{\\sim} \\left(0, \\sigma^2\\right)\\). Since the random errors are centered around zero (i.e., \\(E\\left(\\epsilon\\right) = 0\\)), linear regression is really a problem of estimating a conditional mean:\n\\[\n  E\\left(Y_i | X_i\\right) = \\beta_0 + \\beta_1 X_i.\n\\]\nFor brevity, we often drop the conditional piece and write \\(E\\left(Y | X\\right) = E\\left(Y\\right)\\). Consequently, the interpretation of the coefficients is in terms of the average, or mean response. For example, the intercept \\(\\beta_0\\) represents the average response value when \\(X = 0\\) (it is often not meaningful or of interest and is sometimes referred to as a bias term). The slope \\(\\beta_1\\) represents the increase in the average response per one-unit increase in \\(X\\) (i.e., it is a rate of change).\nSo what are the coefficients of our best fit line that characterizes the relationship between Gr_Liv_Area and Sale_Price? We can get that by fitting an SLR model where Sale_Price is our response variable and Gr_Liv_Area is our single predictor variable.\nOnce our model is fit we can extract our fitted model results with tidy():\n\nmodel1 &lt;- linear_reg() %&gt;%\n   fit(Sale_Price ~ Gr_Liv_Area, data = ames_train)\n\ntidy(model1)\n## # A tibble: 2 × 5\n##   term        estimate std.error statistic   p.value\n##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n## 1 (Intercept)   15938.   3852.        4.14 3.65e-  5\n## 2 Gr_Liv_Area     110.      2.42     45.3  5.17e-311\n\nThe estimated coefficients from our model are \\(b_0 =\\) 15938.17 and \\(b_1 =\\) 109.67. To interpret, we estimate that the mean selling price increases by 109.67 for each additional one square foot of above ground living space.\nWith these coefficients, we can look at our scatter plot again (this time with the x & y axes formatted) and compare the characterization of our regression line with the coefficients. This simple description of the relationship between the sale price and square footage using a single number (i.e., the slope) is what makes linear regression such an intuitive and popular modeling tool.\n\nggplot(ames_train, aes(Gr_Liv_Area, Sale_Price)) +\n   geom_point(size = 1.5, alpha = .25) +\n   geom_smooth(method = \"lm\", se = FALSE) +\n   scale_x_continuous(labels = scales::comma) +\n   scale_y_continuous(labels = scales::dollar)\n\n\n\n\n\n\n\n\n\n\n3.3.2 Estimation\nThis is great but you may still be asking how we are estimating the coefficients? Ideally, we want estimates of \\(b_0\\) and \\(b_1\\) that give us the “best fitting” line represented in the previous plot. But what is meant by “best fitting”? The most common approach is to use the method of least squares (LS) estimation; this form of linear regression is often referred to as ordinary least squares (OLS) regression. There are multiple ways to measure “best fitting”, but the LS criterion finds the “best fitting” line by minimizing the residual sum of squares (RSS).\nBefore we mathematically define RSS, let’s first define what a residual is. Let’s look at a single home. This home has 3,608 square feet of living space and sold for $475,000. In other words, \\(x = 3608\\) and \\(y = 475000\\).\n\n## # A tibble: 1 × 2\n##   Gr_Liv_Area Sale_Price\n##         &lt;int&gt;      &lt;int&gt;\n## 1        3608     475000\n\nBased on our linear regression model (or the intercept and slope we identified from our model) our best fit line estimates that this house’s sale price is\n\\[\\widehat{Y_i} = b_0 + b_1 \\times X_i = 15938.1733 + 109.6675 \\times 3608 = 411618.5\\]\nWe can visualize this in our plot where we have the actual Sale_Price (orange) and the estimated Sale_Price based on our fitted line. The difference between these two values (\\(Y_i - \\widehat{Y_i} = 475000 - 411618.5 = 63381.5\\)) is what we call our residual. It is considered the error for this observation, which we can visualize with the red line.\n\n\n\n\n\n\n\n\n\nNow, if we look across all our data points you will see that each one has a residual associated with it. In the right plot, the vertical lines represent the individual residuals/errors associated with each observation.\n\n\n\n\n\nThe least squares fit from regressing sale price on living space for the the Ames housing data. Left: Fitted regression line. Right: Fitted regression line with vertical grey bars representing the residuals.\n\n\n\n\nThe OLS criterion identifies the “best fitting” line that minimizes the sum of squares of these residuals. Mathematically, this is computed by taking the sum of the squared residuals (or as stated before the residual sum of squares –&gt; “RSS”).\n\\[\nRSS = \\sum_{i=1}^n\\left(Y_i - \\widehat{Y_i}\\right)^2\n\\]\nwhere \\(Y_i\\) and \\(\\widehat{Y_i}\\) just mean the actual and predicted response values for the ith observation.\nOne drawback of the LS procedure in linear regression is that it only provides estimates of the coefficients; it does not provide an estimate of the error variance \\(\\sigma^2\\)! LS also makes no assumptions about the random errors. These assumptions are important for inference and in estimating the error variance which we’re assuming is a constant value \\(\\sigma^2\\). One way to estimate \\(\\sigma^2\\) (which is required for characterizing the variability of our fitted model), is to use the method of maximum likelihood (ML) estimation (see Kutner et al. (2005) Section 1.7 for details). The ML procedure requires that we assume a particular distribution for the random errors. Most often, we assume the errors to be normally distributed. In practice, under the usual assumptions stated above, an unbiased estimate of the error variance is given as the sum of the squared residuals divided by \\(n - p\\) (where \\(p\\) is the number of regression coefficients or parameters in the model):\n\\[\\begin{equation}\n  \\widehat{\\sigma}^2 = \\frac{1}{n - p}\\sum_{i = 1} ^ n r_i ^ 2,\n\\end{equation}\\]\nwhere \\(r_i = \\left(Y_i - \\widehat{Y}_i\\right)\\) is referred to as the \\(i\\)th residual (i.e., the difference between the \\(i\\)th observed and predicted response value). The quantity \\(\\widehat{\\sigma}^2\\) is also referred to as the mean square error (MSE) and its square root is denoted RMSE (see Section Section 2.5.1 for discussion on these metrics).\nFor our SLR model, we can extract the RMSE metric and others using the glance() function:\n\nglance(model1) %&gt;%\n   select(sigma) %&gt;%\n   mutate(RMSE = sigma, MSE = RMSE^2)\n## # A tibble: 1 × 3\n##    sigma   RMSE         MSE\n##    &lt;dbl&gt;  &lt;dbl&gt;       &lt;dbl&gt;\n## 1 56788. 56788. 3224869786.\n\n\n\n\n\n\n\nTypically, these error metrics are computed on a separate validation set discussed in Section Section 2.5 or using cross-validation as will be discussed in a future chapter; however, they can also be computed on the same training data the model was trained on as illustrated here.\n\n\n\n\n\n3.3.3 Inference\nLet’s go back to our model1 results that show the \\(b_0\\) and \\(b_1\\) coefficient values:\n\ntidy(model1)\n## # A tibble: 2 × 5\n##   term        estimate std.error statistic   p.value\n##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n## 1 (Intercept)   15938.   3852.        4.14 3.65e-  5\n## 2 Gr_Liv_Area     110.      2.42     45.3  5.17e-311\n\nNote that we call these coefficient values “estimates.” Due to various reasons we should always assume that there is some variability in our estimated coefficient values. The variability of an estimate is often measured by its standard error (SE)—the square root of its variance. Since we assume that the errors in the linear regression model are \\(\\stackrel{iid}{\\sim} \\left(0, \\sigma^2\\right)\\), then simple expressions for the SEs of the estimated coefficients exist and were computed for us and displayed in the column labeled std.error in the output from tidy().\nFrom this, we can also derive simple \\(t\\)-tests to understand if the individual coefficients are statistically significant from zero. The t-statistics for such a test are nothing more than the estimated coefficients divided by their corresponding estimated standard errors (i.e., in the output from tidy(), t value (aka statistic) = estimate / std.error). The reported t-statistics measure the number of standard deviations each coefficient is away from 0. Thus, large t-statistics (greater than two in absolute value, say) roughly indicate statistical significance at the \\(\\alpha = 0.05\\) level. The p-values for these tests are also reported by tidy() in the column labeled p.value.\n\n\n\n\n\n\nThis may seem quite complicated but don’t worry, R will do the heavy lifting for us. Just realize we can use these additional statistics provided in our model summary to tell us if the predictor variable (Gr_Liv_Area in our example) has a statistically significant relationship with our response variable.\n\n\n\nWhen the p.value for a given coefficient is quite small (i.e. p.value &lt; 0.005), that is a good indication that the estimate for that coefficient is statistically different than zero. For example, the p.value for the Gr_Liv_Area coefficient is 5.17e-311 (basically zero). This means that the estimated coefficient value of 109.6675 is statistically different than zero.\nLet’s look at this from another perspective. Under the same assumptions, we can also derive confidence intervals for the coefficients. The formula for the traditional \\(100\\left(1 - \\alpha\\right)\\)% confidence interval for \\(\\beta_j\\) is\n\\[\n  \\widehat{\\beta}_j \\pm t_{1 - \\alpha / 2, n - p} \\widehat{SE}\\left(\\widehat{\\beta}_j\\right).\n\\tag{3.2}\\]\nIn R, we can construct such (one-at-a-time) confidence intervals for each coefficient using confint(). For example, a 95% confidence intervals for the coefficients in our SLR example can be computed using\n\nconfint(model1$fit, level = 0.95)\n##                2.5 %     97.5 %\n## (Intercept) 8384.213 23492.1336\n## Gr_Liv_Area  104.920   114.4149\n\nTo interpret, we estimate with 95% confidence that the mean selling price increases between 104.92 and 114.41 for each additional one square foot of above ground living space. We can also conclude that the slope \\(b_1\\) is significantly different from zero (or any other pre-specified value not included in the interval) at the \\(\\alpha = 0.05\\) level (\\(\\alpha = 0.05\\) because we just take 1 - confidence level we are computing so \\(1 - 0.95 = 0.05\\)).\n\n\n\n\n\n\nMost statistical software, including R, will include estimated standard errors, t-statistics, etc. as part of its regression output. However, it is important to remember that such quantities depend on three major assumptions of the linear regression model:\n\nIndependent observations\nThe random errors have mean zero, and constant variance\nThe random errors are normally distributed\n\nIf any or all of these assumptions are violated, then remedial measures need to be taken. For instance, weighted least squares (and other procedures) can be used when the constant variance assumption is violated. Transformations (of both the response and features) can also help to correct departures from these assumptions. The residuals are extremely useful in helping to identify how parametric models depart from such assumptions.\n\n\n\n\n\n3.3.4 Making predictions\nWe’ve created a simple linear regression model to describe the relationship between Gr_Liv_Area and Sale_Price. As we saw in the last chapter, we can make predictions with this model.\n\nmodel1 %&gt;%\n   predict(ames_train)\n## # A tibble: 2,049 × 1\n##      .pred\n##      &lt;dbl&gt;\n##  1 135695.\n##  2 135695.\n##  3 107620.\n##  4  98408.\n##  5 126922.\n##  6 224526.\n##  7 114639.\n##  8 129992.\n##  9 205444.\n## 10 132515.\n## # ℹ 2,039 more rows\n\nAnd we can always add these predictions back to our training data if we want to look at how the predicted values differ from the actual values.\n\nmodel1 %&gt;%\n   predict(ames_train) %&gt;%\n   bind_cols(ames_train) %&gt;%\n   select(Gr_Liv_Area, Sale_Price, .pred)\n## # A tibble: 2,049 × 3\n##    Gr_Liv_Area Sale_Price   .pred\n##          &lt;int&gt;      &lt;int&gt;   &lt;dbl&gt;\n##  1        1092     105500 135695.\n##  2        1092      88000 135695.\n##  3         836     120000 107620.\n##  4         752     125000  98408.\n##  5        1012      67500 126922.\n##  6        1902     112000 224526.\n##  7         900     122000 114639.\n##  8        1040     127000 129992.\n##  9        1728      84900 205444.\n## 10        1063     128000 132515.\n## # ℹ 2,039 more rows\n\n\n\n3.3.5 Assessing model accuracy\nThis allows us to assess the accuracy of our model. Recall from the last module that for regression models we often use mean squared error (MSE) and root mean squared error (RMSE) to quantify the accuracy of our model. These two values are directly correlated to the RSS we discussed above, which determines the best fit line. Let’s illustrate.\n\n3.3.5.1 Training data accuracy\nRecall that the residuals are the differences between the actual \\(y\\) and the estimated \\(\\widehat{y}\\) based on the best fit line.\n\nresiduals &lt;- model1 %&gt;%\n   predict(ames_train) %&gt;%\n   bind_cols(ames_train) %&gt;%\n   select(Gr_Liv_Area, Sale_Price, .pred) %&gt;%\n   mutate(residual = Sale_Price - .pred)\n\nhead(residuals, 5)\n## # A tibble: 5 × 4\n##   Gr_Liv_Area Sale_Price   .pred residual\n##         &lt;int&gt;      &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n## 1        1092     105500 135695.  -30195.\n## 2        1092      88000 135695.  -47695.\n## 3         836     120000 107620.   12380.\n## 4         752     125000  98408.   26592.\n## 5        1012      67500 126922.  -59422.\n\nThe RSS squares these values, sums them, and multiples by 1 divided by the number of observations minus the number of coefficients in our model, which is 2.\n\nresiduals %&gt;%\n   mutate(squared_residuals = residual^2) %&gt;%\n   summarize(sum_of_squared_residuals = sum(squared_residuals), n = n()) %&gt;%\n   mutate(RSS = (1 / (n-2)) * sum_of_squared_residuals)\n## # A tibble: 1 × 3\n##   sum_of_squared_residuals     n         RSS\n##                      &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt;\n## 1                  6.60e12  2049 3224869786.\n\n\n\n\n\n\n\nWhy do we square the residuals? So that both positive and negative deviations of the same amount are treated equally. While taking the absolute value of the residuals would also treat both positive and negative deviations of the same amount equally, squaring the residuals is used for reasons related to calculus: taking derivatives and minimizing functions.\n\n\n\nHowever, when expressing the performance of a model we rarely state the RSS. Instead it is more common to state the average of the squared error, or the MSE as discussed here. Unfortunately, both the RSS and MSE are not very intuitive because the units the metrics are expressed in do have much meaning. So, we usually use the RMSE metric, which simply takes the square root of the MSE metric so that your error metric is in the same units as your response variable.\nWe can manually compute this with the following, which tells us that on average, our linear regression model mispredicts the expected sale price of a home by about $56,760.\n\nresiduals %&gt;%\n   mutate(squared_residuals = residual^2) %&gt;%\n   summarize(\n      MSE = mean(squared_residuals),\n      RMSE = sqrt(MSE)\n      )\n## # A tibble: 1 × 2\n##           MSE   RMSE\n##         &lt;dbl&gt;  &lt;dbl&gt;\n## 1 3221722037. 56760.\n\nWe could also compute this using the rmse() function we saw in the last module:\n\nmodel1 %&gt;%\n   predict(ames_train) %&gt;%\n   bind_cols(ames_train) %&gt;%\n   rmse(truth = Sale_Price, estimate = .pred)\n## # A tibble: 1 × 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 rmse    standard      56760.\n\n\n\n3.3.5.2 Test data accuracy\nRecall that a major goal of the machine learning process is to find a model that most accurately predicts future values based on a set of features. In other words, we want an algorithm that not only fits well to our past data, but more importantly, one that predicts a future outcome accurately. In the last chapter we called this our generalization error.\nSo, ultimately, we want to understand how well our model will generalize to unseen data. To do this we need to compute the RMSE of our model on our test set.\n\n\n\n\n\n\nHere, we see that our test RMSE is right around the same as our training data. As we’ll see in later chapters, this is not always the case.\n\n\n\n\nmodel1 %&gt;%\n   predict(ames_test) %&gt;%\n   bind_cols(ames_test) %&gt;%\n   rmse(truth = Sale_Price, estimate = .pred)\n## # A tibble: 1 × 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 rmse    standard      55942.\n\n\n\n\n3.3.6 Knowledge check\n\n\n\n\n\n\nLet’s revisit the relationship between Year_Built and Sale_Price. Using the ames_train data:\n\nVisualize the relationship between these two variables.\nCompute their correlation.\nCreate a simple linear regression model where Sale_Price is a function of Year_Built.\nInterpret the coefficient for Year_Built.\nWhat is the 95% confidence interval for this coefficient and can we confidently say it is statistically different than zero?\nUsing this model, make predictions using the test data. What is the predicted value for the first home in the test data?\nCompute and interpret the generalization RMSE for this model. How does this model compare to the model based on Gr_Liv_Area?",
    "crumbs": [
      "Supervised Learning",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Linear regression</span>"
    ]
  },
  {
    "objectID": "03-slr.html#multiple-linear-regression",
    "href": "03-slr.html#multiple-linear-regression",
    "title": "3  Linear regression",
    "section": "3.4 Multiple linear regression",
    "text": "3.4 Multiple linear regression\nTBD",
    "crumbs": [
      "Supervised Learning",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Linear regression</span>"
    ]
  },
  {
    "objectID": "03-slr.html#exercises",
    "href": "03-slr.html#exercises",
    "title": "3  Linear regression",
    "section": "3.5 Exercises",
    "text": "3.5 Exercises\n\n\n\n\n\n\nWe’ll continue working with the Chicago ridership data we used for the exercises in the previous chapter.\n\nLoad the Chicago ridership data set and split the data into a training set and test set using a 70-30% split.\nUsing the training data\n\nVisualize the relationship between the Ashland and ridership variables.\nCompute the correlation between these two features.\nCreate a simple linear regression model with ridership as the response variable and Ashland as the feature variable.\nInterpret the feature’s coefficient.\nWhat is the model’s generalization error?\n\nNow pick one of the weather_ feature variables and repeat the process in #2.\n\n\n\n\n\n\n\n\nFaraway, Julian J. 2016. Linear Models with r. Chapman; Hall/CRC.\n\n\nKutner, M. H., C. J. Nachtsheim, J. Neter, and W. Li. 2005. Applied Linear Statistical Models. 5th ed. McGraw Hill.\n\n\nLipovetsky, Stan. 2020. Taylor & Francis.",
    "crumbs": [
      "Supervised Learning",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Linear regression</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Breiman, Leo et al. 2001. “Statistical Modeling: The Two Cultures\n(with Comments and a Rejoinder by the Author).” Statistical\nScience 16 (3): 199–231.\n\n\nBuckland, Michael, and Fredric Gey. 1994. “The Relationship\nBetween Recall and Precision.” Journal of the American\nSociety for Information Science 45 (1): 12–19.\n\n\nChawla, Nitesh V, Kevin W Bowyer, Lawrence O Hall, and W Philip\nKegelmeyer. 2002. “SMOTE: Synthetic Minority over-Sampling\nTechnique.” Journal of Artificial Intelligence Research\n16: 321–57.\n\n\nEfron, Bradley, and Trevor Hastie. 2016. Computer Age Statistical\nInference. Vol. 5. Cambridge University Press.\n\n\nFaraway, Julian J. 2016. Linear Models with r. Chapman;\nHall/CRC.\n\n\nGoodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. Deep\nLearning. Vol. 1. MIT Press Cambridge.\n\n\nHarrell, Frank. 2017. “Classification Vs. Prediction.”\n2017. https://www.fharrell.com/post/classification/.\n\n\nHastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. The\nElements of Statistical Learning: Data Mining, Inference, and\nPrediction. Vol. 2. Springer Science+ Business Media.\n\n\nKuhn, Max, and Kjell Johnson. 2013. Applied Predictive\nModeling. Vol. 26. Springer.\n\n\n———. 2019. Feature Engineering and Selection: A Practical Approach\nfor Predictive Models. Chapman; Hall/CRC.\n\n\nKutner, M. H., C. J. Nachtsheim, J. Neter, and W. Li. 2005. Applied\nLinear Statistical Models. 5th ed. McGraw Hill.\n\n\nLipovetsky, Stan. 2020. Taylor & Francis.\n\n\nMnih, Volodymyr, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis\nAntonoglou, Daan Wierstra, and Martin A. Riedmiller. 2013.\n“Playing Atari with Deep Reinforcement Learning.”\nCoRR abs/1312.5602. http://arxiv.org/abs/1312.5602.\n\n\nPowell, Warren B. 2021. “From Reinforcement Learning to Optimal\nControl: A Unified Framework for Sequential Decisions.” In\nHandbook of Reinforcement Learning and Control, 29–74.\nSpringer.\n\n\nSutton, Richard S, and Andrew G Barto. 2018. Reinforcement Learning:\nAn Introduction. MIT press.\n\n\nSzepesvári, Csaba. 2022. Algorithms for Reinforcement Learning.\nSpringer Nature.\n\n\nWickham, Hadley. 2014. Advanced r. CRC Press.\n\n\nWickham, Hadley, and Garrett Grolemund. 2016. R for Data Science:\nImport, Tidy, Transform, Visualize, and Model Data. O’Reilly Media,\nInc.\n\n\nWolpert, David H. 1996. “The Lack of a Priori Distinctions Between\nLearning Algorithms.” Neural Computation 8 (7): 1341–90.",
    "crumbs": [
      "Supervised Learning",
      "References"
    ]
  }
]